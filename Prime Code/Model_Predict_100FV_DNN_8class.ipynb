{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from keras.utils import np_utils\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.pipeline import Pipeline\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "import matplotlib.pyplot as plt\n",
    "import keras.initializers \n",
    "from keras import regularizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# If GPU is not available: \n",
    "# GPU_USE = '/cpu:0'\n",
    "# config = tf.ConfigProto(device_count = {\"GPU\": 0})\n",
    "\n",
    "\n",
    "# If GPU is available: \n",
    "config = tf.ConfigProto()\n",
    "config.log_device_placement = True\n",
    "config.allow_soft_placement = True\n",
    "config.gpu_options.allocator_type = 'BFC'\n",
    "\n",
    "# Limit the maximum memory used\n",
    "config.gpu_options.per_process_gpu_memory_fraction = 0.1\n",
    "\n",
    "# set session config\n",
    "tf.keras.backend.set_session(tf.Session(config=config))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "FilePath = \"/home/nramvinojen/Programs/Workbench/24Jan2019/\"\n",
    "NewFVlen = 100\n",
    "Class = 8\n",
    "#RunFolder = \"Default\"\n",
    "RunFolder = \"03Feb2019\"\n",
    "\n",
    "Class = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# load dataset\n",
    "dataframe = pd.read_csv(FilePath + \"Runs/\"+ RunFolder + \"/FV100_fromResnet/Fixation_WeightedSum_Combined_Csv/TR_CombinedFixation_FeatureVector.csv\", header=None)\n",
    "X = dataframe.values.astype(float)\n",
    "# load dataset\n",
    "dataframe = pd.read_csv(FilePath +\"Runs/\" + RunFolder + \"/FV2048_Resnet/TR_Label.csv\", header=None)\n",
    "Y_temp = dataframe.values\n",
    "Y = Y_temp[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# encode class values as integers\n",
    "encoder = LabelEncoder()\n",
    "encoder.fit(Y)\n",
    "encoded_Y = encoder.transform(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "y_train_one_hot = tf.keras.utils.to_categorical(Y, Class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# load dataset\n",
    "dataframe = pd.read_csv(FilePath + \"Runs/\"+ RunFolder + \"/FV100_fromResnet/Fixation_WeightedSum_Combined_Csv/Val_CombinedFixation_FeatureVector.csv\", header=None)\n",
    "X_test = dataframe.values.astype(float)\n",
    "\n",
    "\n",
    "dataframe = pd.read_csv(FilePath +\"Runs/\" + RunFolder + \"/FV2048_Resnet/Val_Label.csv\", header=None)\n",
    "Ytest_temp = dataframe.values\n",
    "Y_test = Ytest_temp[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# encode class values as integers\n",
    "encoder = LabelEncoder()\n",
    "encoder.fit(Y_test)\n",
    "encoded_Ytest = encoder.transform(Y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "y_test_one_hot = tf.keras.utils.to_categorical(Y_test, Class)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 28)                2828      \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 28)                0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 8)                 232       \n",
      "=================================================================\n",
      "Total params: 3,060\n",
      "Trainable params: 3,060\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/_impl/keras/backend.py:1456: calling reduce_sum (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "keep_dims is deprecated, use keepdims instead\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/_impl/keras/backend.py:1557: calling reduce_mean (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "keep_dims is deprecated, use keepdims instead\n",
      "Train on 216 samples, validate on 48 samples\n",
      "Epoch 1/1200\n",
      "216/216 [==============================]216/216 [==============================] - 1s 7ms/step - loss: 4.6919 - acc: 0.1481 - val_loss: 3.3851 - val_acc: 0.1667\n",
      "\n",
      "Epoch 2/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 45us/step - loss: 4.7285 - acc: 0.1111 - val_loss: 3.2914 - val_acc: 0.1667\n",
      "\n",
      "Epoch 3/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 39us/step - loss: 4.6442 - acc: 0.1481 - val_loss: 3.2092 - val_acc: 0.1875\n",
      "\n",
      "Epoch 4/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 34us/step - loss: 4.4478 - acc: 0.1528 - val_loss: 3.1328 - val_acc: 0.1875\n",
      "\n",
      "Epoch 5/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 34us/step - loss: 4.3584 - acc: 0.1296 - val_loss: 3.0701 - val_acc: 0.1875\n",
      "\n",
      "Epoch 6/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 32us/step - loss: 4.3683 - acc: 0.1204 - val_loss: 3.0035 - val_acc: 0.1875\n",
      "\n",
      "Epoch 7/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 37us/step - loss: 4.1821 - acc: 0.1574 - val_loss: 2.9338 - val_acc: 0.1875\n",
      "\n",
      "Epoch 8/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 58us/step - loss: 3.9318 - acc: 0.1435 - val_loss: 2.8743 - val_acc: 0.1875\n",
      "\n",
      "Epoch 9/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 45us/step - loss: 3.7839 - acc: 0.1759 - val_loss: 2.8121 - val_acc: 0.1875\n",
      "\n",
      "Epoch 10/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 35us/step - loss: 3.9260 - acc: 0.1389 - val_loss: 2.7619 - val_acc: 0.1875\n",
      "\n",
      "Epoch 11/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 35us/step - loss: 3.8559 - acc: 0.1574 - val_loss: 2.7072 - val_acc: 0.2083\n",
      "\n",
      "Epoch 12/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 32us/step - loss: 3.7142 - acc: 0.1991 - val_loss: 2.6567 - val_acc: 0.2083\n",
      "\n",
      "Epoch 13/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 37us/step - loss: 3.5218 - acc: 0.1713 - val_loss: 2.6116 - val_acc: 0.2083\n",
      "\n",
      "Epoch 14/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 32us/step - loss: 3.4651 - acc: 0.1481 - val_loss: 2.5664 - val_acc: 0.2083\n",
      "\n",
      "Epoch 15/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 34us/step - loss: 3.4390 - acc: 0.1389 - val_loss: 2.5217 - val_acc: 0.2083\n",
      "\n",
      "Epoch 16/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 39us/step - loss: 3.2352 - acc: 0.1296 - val_loss: 2.4826 - val_acc: 0.2083\n",
      "\n",
      "Epoch 17/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 37us/step - loss: 3.2842 - acc: 0.1574 - val_loss: 2.4481 - val_acc: 0.2083\n",
      "\n",
      "Epoch 18/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 36us/step - loss: 3.1032 - acc: 0.1620 - val_loss: 2.4073 - val_acc: 0.2083\n",
      "\n",
      "Epoch 19/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 41us/step - loss: 3.0513 - acc: 0.1481 - val_loss: 2.3797 - val_acc: 0.2292\n",
      "\n",
      "Epoch 20/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 38us/step - loss: 3.1775 - acc: 0.1204 - val_loss: 2.3508 - val_acc: 0.2083\n",
      "\n",
      "Epoch 21/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 33us/step - loss: 3.1484 - acc: 0.1759 - val_loss: 2.3245 - val_acc: 0.2083\n",
      "\n",
      "Epoch 22/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 34us/step - loss: 2.9718 - acc: 0.1759 - val_loss: 2.2970 - val_acc: 0.1875\n",
      "\n",
      "Epoch 23/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 40us/step - loss: 2.9236 - acc: 0.1574 - val_loss: 2.2712 - val_acc: 0.1875\n",
      "\n",
      "Epoch 24/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 41us/step - loss: 2.7940 - acc: 0.1528 - val_loss: 2.2504 - val_acc: 0.2083\n",
      "\n",
      "Epoch 25/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 34us/step - loss: 2.8326 - acc: 0.1574 - val_loss: 2.2273 - val_acc: 0.2083\n",
      "\n",
      "Epoch 26/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 37us/step - loss: 2.8639 - acc: 0.1852 - val_loss: 2.2073 - val_acc: 0.2083\n",
      "\n",
      "Epoch 27/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 34us/step - loss: 2.6569 - acc: 0.1713 - val_loss: 2.1882 - val_acc: 0.1667\n",
      "\n",
      "Epoch 28/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 33us/step - loss: 2.8144 - acc: 0.1574 - val_loss: 2.1641 - val_acc: 0.1458\n",
      "\n",
      "Epoch 29/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 39us/step - loss: 2.5827 - acc: 0.1574 - val_loss: 2.1398 - val_acc: 0.1458\n",
      "\n",
      "Epoch 30/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 33us/step - loss: 2.6147 - acc: 0.1343 - val_loss: 2.1214 - val_acc: 0.1458\n",
      "\n",
      "Epoch 31/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 35us/step - loss: 2.5861 - acc: 0.1435 - val_loss: 2.0927 - val_acc: 0.1250\n",
      "\n",
      "Epoch 32/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 33us/step - loss: 2.5999 - acc: 0.1620 - val_loss: 2.0777 - val_acc: 0.1250\n",
      "\n",
      "Epoch 33/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 32us/step - loss: 2.5776 - acc: 0.1296 - val_loss: 2.0575 - val_acc: 0.1250\n",
      "\n",
      "Epoch 34/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 32us/step - loss: 2.4509 - acc: 0.1574 - val_loss: 2.0374 - val_acc: 0.1458\n",
      "\n",
      "Epoch 35/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 32us/step - loss: 2.4398 - acc: 0.1944 - val_loss: 2.0173 - val_acc: 0.1667\n",
      "\n",
      "Epoch 36/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 34us/step - loss: 2.3437 - acc: 0.2222 - val_loss: 2.0057 - val_acc: 0.1875\n",
      "\n",
      "Epoch 37/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 33us/step - loss: 2.3054 - acc: 0.2546 - val_loss: 1.9840 - val_acc: 0.2292\n",
      "\n",
      "Epoch 38/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 32us/step - loss: 2.5073 - acc: 0.1528 - val_loss: 1.9724 - val_acc: 0.2500\n",
      "\n",
      "Epoch 39/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 32us/step - loss: 2.3278 - acc: 0.1759 - val_loss: 1.9586 - val_acc: 0.2500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 40/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 32us/step - loss: 2.2324 - acc: 0.1991 - val_loss: 1.9443 - val_acc: 0.2500\n",
      "\n",
      "Epoch 41/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 35us/step - loss: 2.2802 - acc: 0.1852 - val_loss: 1.9399 - val_acc: 0.2500\n",
      "\n",
      "Epoch 42/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 33us/step - loss: 2.2586 - acc: 0.2222 - val_loss: 1.9284 - val_acc: 0.2500\n",
      "\n",
      "Epoch 43/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 33us/step - loss: 2.2686 - acc: 0.2083 - val_loss: 1.9243 - val_acc: 0.2292\n",
      "\n",
      "Epoch 44/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 39us/step - loss: 2.2563 - acc: 0.2130 - val_loss: 1.9223 - val_acc: 0.2500\n",
      "\n",
      "Epoch 45/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 31us/step - loss: 2.2309 - acc: 0.1991 - val_loss: 1.9141 - val_acc: 0.2500\n",
      "\n",
      "Epoch 46/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 46us/step - loss: 2.2551 - acc: 0.1667 - val_loss: 1.9097 - val_acc: 0.2708\n",
      "\n",
      "Epoch 47/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 35us/step - loss: 2.1810 - acc: 0.2546 - val_loss: 1.9064 - val_acc: 0.2917\n",
      "\n",
      "Epoch 48/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 49us/step - loss: 2.1168 - acc: 0.2222 - val_loss: 1.8958 - val_acc: 0.2917\n",
      "\n",
      "Epoch 49/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 51us/step - loss: 2.2297 - acc: 0.2269 - val_loss: 1.8871 - val_acc: 0.2708\n",
      "\n",
      "Epoch 50/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 74us/step - loss: 2.1895 - acc: 0.2315 - val_loss: 1.8927 - val_acc: 0.2917\n",
      "\n",
      "Epoch 51/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 72us/step - loss: 2.1259 - acc: 0.2407 - val_loss: 1.8801 - val_acc: 0.2708\n",
      "\n",
      "Epoch 52/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 113us/step - loss: 2.1138 - acc: 0.1991 - val_loss: 1.8670 - val_acc: 0.2708\n",
      "\n",
      "Epoch 53/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 230us/step - loss: 2.1343 - acc: 0.2083 - val_loss: 1.8701 - val_acc: 0.2708\n",
      "\n",
      "Epoch 54/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 105us/step - loss: 2.0716 - acc: 0.2130 - val_loss: 1.8734 - val_acc: 0.2708\n",
      "\n",
      "Epoch 55/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 116us/step - loss: 1.9808 - acc: 0.2593 - val_loss: 1.8565 - val_acc: 0.2708\n",
      "\n",
      "Epoch 56/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 110us/step - loss: 2.0197 - acc: 0.2870 - val_loss: 1.8400 - val_acc: 0.2500\n",
      "\n",
      "Epoch 57/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 111us/step - loss: 2.0391 - acc: 0.2176 - val_loss: 1.8440 - val_acc: 0.2292\n",
      "\n",
      "Epoch 58/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 105us/step - loss: 2.1272 - acc: 0.2315 - val_loss: 1.8472 - val_acc: 0.2292\n",
      "\n",
      "Epoch 59/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 109us/step - loss: 1.9608 - acc: 0.2870 - val_loss: 1.8417 - val_acc: 0.2292\n",
      "\n",
      "Epoch 60/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 107us/step - loss: 1.9155 - acc: 0.2917 - val_loss: 1.8358 - val_acc: 0.2500\n",
      "\n",
      "Epoch 61/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 105us/step - loss: 2.0269 - acc: 0.3241 - val_loss: 1.8249 - val_acc: 0.2500\n",
      "\n",
      "Epoch 62/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 110us/step - loss: 2.0463 - acc: 0.2407 - val_loss: 1.8351 - val_acc: 0.2708\n",
      "\n",
      "Epoch 63/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 110us/step - loss: 2.0116 - acc: 0.2546 - val_loss: 1.8283 - val_acc: 0.2708\n",
      "\n",
      "Epoch 64/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 106us/step - loss: 2.0979 - acc: 0.2639 - val_loss: 1.8245 - val_acc: 0.2708\n",
      "\n",
      "Epoch 65/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 98us/step - loss: 2.0980 - acc: 0.2407 - val_loss: 1.8263 - val_acc: 0.2708\n",
      "\n",
      "Epoch 66/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 225us/step - loss: 1.9459 - acc: 0.2685 - val_loss: 1.8165 - val_acc: 0.2708\n",
      "\n",
      "Epoch 67/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 111us/step - loss: 1.9299 - acc: 0.2731 - val_loss: 1.8196 - val_acc: 0.2500\n",
      "\n",
      "Epoch 68/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 104us/step - loss: 1.9762 - acc: 0.2824 - val_loss: 1.8133 - val_acc: 0.2708\n",
      "\n",
      "Epoch 69/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 104us/step - loss: 1.9429 - acc: 0.3194 - val_loss: 1.8054 - val_acc: 0.2500\n",
      "\n",
      "Epoch 70/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 101us/step - loss: 1.9586 - acc: 0.2546 - val_loss: 1.8156 - val_acc: 0.2500\n",
      "\n",
      "Epoch 71/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 138us/step - loss: 1.9911 - acc: 0.3009 - val_loss: 1.7959 - val_acc: 0.2708\n",
      "\n",
      "Epoch 72/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 112us/step - loss: 1.9271 - acc: 0.3148 - val_loss: 1.7934 - val_acc: 0.2917\n",
      "\n",
      "Epoch 73/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 106us/step - loss: 2.0120 - acc: 0.2500 - val_loss: 1.7865 - val_acc: 0.3125\n",
      "\n",
      "Epoch 74/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 110us/step - loss: 1.9210 - acc: 0.2963 - val_loss: 1.7986 - val_acc: 0.3125\n",
      "\n",
      "Epoch 75/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 98us/step - loss: 1.8496 - acc: 0.3380 - val_loss: 1.7836 - val_acc: 0.3125\n",
      "\n",
      "Epoch 76/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 148us/step - loss: 2.0200 - acc: 0.2639 - val_loss: 1.7825 - val_acc: 0.3125\n",
      "\n",
      "Epoch 77/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 87us/step - loss: 1.9273 - acc: 0.2778 - val_loss: 1.7800 - val_acc: 0.3125\n",
      "\n",
      "Epoch 78/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 91us/step - loss: 1.9569 - acc: 0.2963 - val_loss: 1.7750 - val_acc: 0.3333\n",
      "\n",
      "Epoch 79/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 86us/step - loss: 1.8907 - acc: 0.3009 - val_loss: 1.7640 - val_acc: 0.3125\n",
      "\n",
      "Epoch 80/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 108us/step - loss: 1.9379 - acc: 0.2778 - val_loss: 1.7610 - val_acc: 0.3542\n",
      "\n",
      "Epoch 81/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 95us/step - loss: 1.9049 - acc: 0.2593 - val_loss: 1.7587 - val_acc: 0.3333\n",
      "\n",
      "Epoch 82/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 102us/step - loss: 1.8370 - acc: 0.3519 - val_loss: 1.7542 - val_acc: 0.3958\n",
      "\n",
      "Epoch 83/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 101us/step - loss: 1.8097 - acc: 0.3287 - val_loss: 1.7552 - val_acc: 0.3750\n",
      "\n",
      "Epoch 84/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 83us/step - loss: 1.8240 - acc: 0.3287 - val_loss: 1.7435 - val_acc: 0.3958\n",
      "\n",
      "Epoch 85/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 110us/step - loss: 1.8894 - acc: 0.3380 - val_loss: 1.7352 - val_acc: 0.3750\n",
      "\n",
      "Epoch 86/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 82us/step - loss: 1.8903 - acc: 0.3333 - val_loss: 1.7352 - val_acc: 0.3750\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 87/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 98us/step - loss: 1.8715 - acc: 0.3241 - val_loss: 1.7184 - val_acc: 0.3750\n",
      "\n",
      "Epoch 88/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 94us/step - loss: 1.8080 - acc: 0.3472 - val_loss: 1.7193 - val_acc: 0.3750\n",
      "\n",
      "Epoch 89/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 100us/step - loss: 1.8517 - acc: 0.3241 - val_loss: 1.7186 - val_acc: 0.3750\n",
      "\n",
      "Epoch 90/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 94us/step - loss: 1.8721 - acc: 0.3241 - val_loss: 1.7197 - val_acc: 0.3750\n",
      "\n",
      "Epoch 91/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 80us/step - loss: 1.8733 - acc: 0.3426 - val_loss: 1.7090 - val_acc: 0.3750\n",
      "\n",
      "Epoch 92/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 88us/step - loss: 1.8469 - acc: 0.3426 - val_loss: 1.7039 - val_acc: 0.3958\n",
      "\n",
      "Epoch 93/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 87us/step - loss: 1.8473 - acc: 0.3333 - val_loss: 1.7111 - val_acc: 0.3958\n",
      "\n",
      "Epoch 94/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 98us/step - loss: 1.8216 - acc: 0.3565 - val_loss: 1.7000 - val_acc: 0.4167\n",
      "\n",
      "Epoch 95/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 102us/step - loss: 1.8663 - acc: 0.2639 - val_loss: 1.6877 - val_acc: 0.4167\n",
      "\n",
      "Epoch 96/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 89us/step - loss: 1.7958 - acc: 0.4167 - val_loss: 1.6893 - val_acc: 0.4167\n",
      "\n",
      "Epoch 97/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 100us/step - loss: 1.8308 - acc: 0.3241 - val_loss: 1.6877 - val_acc: 0.4167\n",
      "\n",
      "Epoch 98/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 97us/step - loss: 1.7958 - acc: 0.3611 - val_loss: 1.6936 - val_acc: 0.3958\n",
      "\n",
      "Epoch 99/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 88us/step - loss: 1.8816 - acc: 0.3102 - val_loss: 1.6984 - val_acc: 0.3958\n",
      "\n",
      "Epoch 100/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 88us/step - loss: 1.8381 - acc: 0.3426 - val_loss: 1.6887 - val_acc: 0.4167\n",
      "\n",
      "Epoch 101/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 81us/step - loss: 1.7747 - acc: 0.3241 - val_loss: 1.6897 - val_acc: 0.4167\n",
      "\n",
      "Epoch 102/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 95us/step - loss: 1.7319 - acc: 0.3472 - val_loss: 1.6815 - val_acc: 0.3958\n",
      "\n",
      "Epoch 103/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 90us/step - loss: 1.7778 - acc: 0.3611 - val_loss: 1.6828 - val_acc: 0.3750\n",
      "\n",
      "Epoch 104/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 46us/step - loss: 1.8122 - acc: 0.3148 - val_loss: 1.6902 - val_acc: 0.4167\n",
      "\n",
      "Epoch 105/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 38us/step - loss: 1.8624 - acc: 0.2917 - val_loss: 1.6864 - val_acc: 0.4167\n",
      "\n",
      "Epoch 106/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 32us/step - loss: 1.8456 - acc: 0.3009 - val_loss: 1.6895 - val_acc: 0.4167\n",
      "\n",
      "Epoch 107/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 50us/step - loss: 1.7539 - acc: 0.3657 - val_loss: 1.6800 - val_acc: 0.4167\n",
      "\n",
      "Epoch 108/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 32us/step - loss: 1.7737 - acc: 0.3380 - val_loss: 1.6795 - val_acc: 0.4167\n",
      "\n",
      "Epoch 109/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 33us/step - loss: 1.8480 - acc: 0.3380 - val_loss: 1.6717 - val_acc: 0.4167\n",
      "\n",
      "Epoch 110/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 34us/step - loss: 1.8138 - acc: 0.3241 - val_loss: 1.6670 - val_acc: 0.4375\n",
      "\n",
      "Epoch 111/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 42us/step - loss: 1.7627 - acc: 0.3657 - val_loss: 1.6709 - val_acc: 0.4167\n",
      "\n",
      "Epoch 112/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 33us/step - loss: 1.7361 - acc: 0.3472 - val_loss: 1.6698 - val_acc: 0.4167\n",
      "\n",
      "Epoch 113/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 36us/step - loss: 1.7514 - acc: 0.3796 - val_loss: 1.6643 - val_acc: 0.3958\n",
      "\n",
      "Epoch 114/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 33us/step - loss: 1.7314 - acc: 0.3426 - val_loss: 1.6617 - val_acc: 0.4167\n",
      "\n",
      "Epoch 115/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 38us/step - loss: 1.7770 - acc: 0.3380 - val_loss: 1.6609 - val_acc: 0.4375\n",
      "\n",
      "Epoch 116/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 34us/step - loss: 1.7697 - acc: 0.3657 - val_loss: 1.6673 - val_acc: 0.4167\n",
      "\n",
      "Epoch 117/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 34us/step - loss: 1.8006 - acc: 0.3241 - val_loss: 1.6661 - val_acc: 0.4167\n",
      "\n",
      "Epoch 118/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 32us/step - loss: 1.7721 - acc: 0.3194 - val_loss: 1.6662 - val_acc: 0.4375\n",
      "\n",
      "Epoch 119/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 33us/step - loss: 1.7678 - acc: 0.3704 - val_loss: 1.6588 - val_acc: 0.4375\n",
      "\n",
      "Epoch 120/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 32us/step - loss: 1.7630 - acc: 0.3935 - val_loss: 1.6565 - val_acc: 0.3958\n",
      "\n",
      "Epoch 121/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 35us/step - loss: 1.7784 - acc: 0.3565 - val_loss: 1.6560 - val_acc: 0.4167\n",
      "\n",
      "Epoch 122/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 36us/step - loss: 1.7645 - acc: 0.3519 - val_loss: 1.6554 - val_acc: 0.4583\n",
      "\n",
      "Epoch 123/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 43us/step - loss: 1.7521 - acc: 0.3611 - val_loss: 1.6601 - val_acc: 0.4167\n",
      "\n",
      "Epoch 124/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 39us/step - loss: 1.7715 - acc: 0.3333 - val_loss: 1.6580 - val_acc: 0.3958\n",
      "\n",
      "Epoch 125/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 33us/step - loss: 1.8249 - acc: 0.2963 - val_loss: 1.6590 - val_acc: 0.4583\n",
      "\n",
      "Epoch 126/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 33us/step - loss: 1.8035 - acc: 0.3380 - val_loss: 1.6570 - val_acc: 0.4167\n",
      "\n",
      "Epoch 127/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 34us/step - loss: 1.7214 - acc: 0.3611 - val_loss: 1.6496 - val_acc: 0.4167\n",
      "\n",
      "Epoch 128/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 35us/step - loss: 1.7360 - acc: 0.3704 - val_loss: 1.6531 - val_acc: 0.4375\n",
      "\n",
      "Epoch 129/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 37us/step - loss: 1.6981 - acc: 0.3657 - val_loss: 1.6491 - val_acc: 0.4375\n",
      "\n",
      "Epoch 130/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 48us/step - loss: 1.6917 - acc: 0.3889 - val_loss: 1.6425 - val_acc: 0.4375\n",
      "\n",
      "Epoch 131/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 35us/step - loss: 1.6874 - acc: 0.3750 - val_loss: 1.6343 - val_acc: 0.4375\n",
      "\n",
      "Epoch 132/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 34us/step - loss: 1.7209 - acc: 0.3611 - val_loss: 1.6349 - val_acc: 0.3958\n",
      "\n",
      "Epoch 133/1200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "216/216 [==============================]216/216 [==============================] - 0s 38us/step - loss: 1.7184 - acc: 0.4491 - val_loss: 1.6340 - val_acc: 0.4375\n",
      "\n",
      "Epoch 134/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 39us/step - loss: 1.6639 - acc: 0.4120 - val_loss: 1.6301 - val_acc: 0.4583\n",
      "\n",
      "Epoch 135/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 33us/step - loss: 1.6986 - acc: 0.3843 - val_loss: 1.6317 - val_acc: 0.4375\n",
      "\n",
      "Epoch 136/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 34us/step - loss: 1.6989 - acc: 0.4167 - val_loss: 1.6378 - val_acc: 0.3958\n",
      "\n",
      "Epoch 137/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 35us/step - loss: 1.6747 - acc: 0.3981 - val_loss: 1.6358 - val_acc: 0.4583\n",
      "\n",
      "Epoch 138/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 44us/step - loss: 1.7743 - acc: 0.3750 - val_loss: 1.6340 - val_acc: 0.4375\n",
      "\n",
      "Epoch 139/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 34us/step - loss: 1.7529 - acc: 0.3704 - val_loss: 1.6320 - val_acc: 0.4375\n",
      "\n",
      "Epoch 140/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 32us/step - loss: 1.6953 - acc: 0.3981 - val_loss: 1.6339 - val_acc: 0.4583\n",
      "\n",
      "Epoch 141/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 34us/step - loss: 1.7172 - acc: 0.3565 - val_loss: 1.6300 - val_acc: 0.4375\n",
      "\n",
      "Epoch 142/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 36us/step - loss: 1.7374 - acc: 0.3981 - val_loss: 1.6334 - val_acc: 0.4167\n",
      "\n",
      "Epoch 143/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 33us/step - loss: 1.7069 - acc: 0.4028 - val_loss: 1.6318 - val_acc: 0.4375\n",
      "\n",
      "Epoch 144/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 32us/step - loss: 1.7251 - acc: 0.3472 - val_loss: 1.6324 - val_acc: 0.4375\n",
      "\n",
      "Epoch 145/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 35us/step - loss: 1.7595 - acc: 0.4120 - val_loss: 1.6322 - val_acc: 0.4167\n",
      "\n",
      "Epoch 146/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 35us/step - loss: 1.6978 - acc: 0.4120 - val_loss: 1.6325 - val_acc: 0.4167\n",
      "\n",
      "Epoch 147/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 31us/step - loss: 1.6504 - acc: 0.3843 - val_loss: 1.6245 - val_acc: 0.4167\n",
      "\n",
      "Epoch 148/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 32us/step - loss: 1.7710 - acc: 0.3241 - val_loss: 1.6253 - val_acc: 0.4375\n",
      "\n",
      "Epoch 149/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 55us/step - loss: 1.7320 - acc: 0.3519 - val_loss: 1.6203 - val_acc: 0.4167\n",
      "\n",
      "Epoch 150/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 43us/step - loss: 1.7357 - acc: 0.3889 - val_loss: 1.6210 - val_acc: 0.4375\n",
      "\n",
      "Epoch 151/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 42us/step - loss: 1.6887 - acc: 0.3611 - val_loss: 1.6239 - val_acc: 0.4167\n",
      "\n",
      "Epoch 152/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 42us/step - loss: 1.7680 - acc: 0.3750 - val_loss: 1.6226 - val_acc: 0.4167\n",
      "\n",
      "Epoch 153/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 37us/step - loss: 1.7121 - acc: 0.3935 - val_loss: 1.6214 - val_acc: 0.4375\n",
      "\n",
      "Epoch 154/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 41us/step - loss: 1.6993 - acc: 0.3611 - val_loss: 1.6214 - val_acc: 0.4167\n",
      "\n",
      "Epoch 155/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 41us/step - loss: 1.7180 - acc: 0.3750 - val_loss: 1.6220 - val_acc: 0.4167\n",
      "\n",
      "Epoch 156/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 39us/step - loss: 1.6758 - acc: 0.4120 - val_loss: 1.6201 - val_acc: 0.4375\n",
      "\n",
      "Epoch 157/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 43us/step - loss: 1.6996 - acc: 0.4074 - val_loss: 1.6190 - val_acc: 0.4375\n",
      "\n",
      "Epoch 158/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 34us/step - loss: 1.7325 - acc: 0.3796 - val_loss: 1.6198 - val_acc: 0.4167\n",
      "\n",
      "Epoch 159/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 48us/step - loss: 1.7590 - acc: 0.3426 - val_loss: 1.6199 - val_acc: 0.4583\n",
      "\n",
      "Epoch 160/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 42us/step - loss: 1.7063 - acc: 0.4028 - val_loss: 1.6194 - val_acc: 0.4583\n",
      "\n",
      "Epoch 161/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 41us/step - loss: 1.5863 - acc: 0.4537 - val_loss: 1.6117 - val_acc: 0.4583\n",
      "\n",
      "Epoch 162/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 75us/step - loss: 1.7389 - acc: 0.3287 - val_loss: 1.6071 - val_acc: 0.4583\n",
      "\n",
      "Epoch 163/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 96us/step - loss: 1.6444 - acc: 0.3657 - val_loss: 1.6171 - val_acc: 0.4375\n",
      "\n",
      "Epoch 164/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 227us/step - loss: 1.6490 - acc: 0.3843 - val_loss: 1.6227 - val_acc: 0.4167\n",
      "\n",
      "Epoch 165/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 100us/step - loss: 1.7029 - acc: 0.3472 - val_loss: 1.6195 - val_acc: 0.4167\n",
      "\n",
      "Epoch 166/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 116us/step - loss: 1.7108 - acc: 0.3981 - val_loss: 1.6118 - val_acc: 0.4375\n",
      "\n",
      "Epoch 167/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 110us/step - loss: 1.6433 - acc: 0.3935 - val_loss: 1.6150 - val_acc: 0.4583\n",
      "\n",
      "Epoch 168/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 105us/step - loss: 1.7822 - acc: 0.3380 - val_loss: 1.6111 - val_acc: 0.4375\n",
      "\n",
      "Epoch 169/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 110us/step - loss: 1.7204 - acc: 0.3241 - val_loss: 1.6171 - val_acc: 0.4375\n",
      "\n",
      "Epoch 170/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 107us/step - loss: 1.6603 - acc: 0.4259 - val_loss: 1.6137 - val_acc: 0.4375\n",
      "\n",
      "Epoch 171/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 96us/step - loss: 1.6122 - acc: 0.4074 - val_loss: 1.6113 - val_acc: 0.4375\n",
      "\n",
      "Epoch 172/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 106us/step - loss: 1.7177 - acc: 0.3102 - val_loss: 1.6137 - val_acc: 0.4167\n",
      "\n",
      "Epoch 173/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 106us/step - loss: 1.7169 - acc: 0.3611 - val_loss: 1.6127 - val_acc: 0.4167\n",
      "\n",
      "Epoch 174/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 101us/step - loss: 1.7446 - acc: 0.3611 - val_loss: 1.6086 - val_acc: 0.4583\n",
      "\n",
      "Epoch 175/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 107us/step - loss: 1.7242 - acc: 0.3611 - val_loss: 1.6124 - val_acc: 0.4375\n",
      "\n",
      "Epoch 176/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 116us/step - loss: 1.6771 - acc: 0.4167 - val_loss: 1.6134 - val_acc: 0.4167\n",
      "\n",
      "Epoch 177/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 235us/step - loss: 1.7053 - acc: 0.3981 - val_loss: 1.6127 - val_acc: 0.4375\n",
      "\n",
      "Epoch 178/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 98us/step - loss: 1.5924 - acc: 0.4167 - val_loss: 1.6044 - val_acc: 0.4375\n",
      "\n",
      "Epoch 179/1200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "216/216 [==============================]216/216 [==============================] - 0s 96us/step - loss: 1.6609 - acc: 0.3796 - val_loss: 1.6027 - val_acc: 0.4375\n",
      "\n",
      "Epoch 180/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 97us/step - loss: 1.6531 - acc: 0.3704 - val_loss: 1.5911 - val_acc: 0.4375\n",
      "\n",
      "Epoch 181/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 106us/step - loss: 1.6800 - acc: 0.3704 - val_loss: 1.5974 - val_acc: 0.4583\n",
      "\n",
      "Epoch 182/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 152us/step - loss: 1.7130 - acc: 0.3704 - val_loss: 1.5923 - val_acc: 0.4583\n",
      "\n",
      "Epoch 183/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 97us/step - loss: 1.7216 - acc: 0.3611 - val_loss: 1.5948 - val_acc: 0.4792\n",
      "\n",
      "Epoch 184/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 114us/step - loss: 1.6947 - acc: 0.3935 - val_loss: 1.5803 - val_acc: 0.4375\n",
      "\n",
      "Epoch 185/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 105us/step - loss: 1.6426 - acc: 0.3889 - val_loss: 1.5823 - val_acc: 0.4375\n",
      "\n",
      "Epoch 186/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 98us/step - loss: 1.6932 - acc: 0.3657 - val_loss: 1.5728 - val_acc: 0.4375\n",
      "\n",
      "Epoch 187/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 138us/step - loss: 1.7408 - acc: 0.3750 - val_loss: 1.5753 - val_acc: 0.4375\n",
      "\n",
      "Epoch 188/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 108us/step - loss: 1.7304 - acc: 0.3750 - val_loss: 1.5773 - val_acc: 0.4375\n",
      "\n",
      "Epoch 189/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 86us/step - loss: 1.6598 - acc: 0.3843 - val_loss: 1.5737 - val_acc: 0.4167\n",
      "\n",
      "Epoch 190/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 87us/step - loss: 1.6688 - acc: 0.3750 - val_loss: 1.5774 - val_acc: 0.4583\n",
      "\n",
      "Epoch 191/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 98us/step - loss: 1.6770 - acc: 0.3565 - val_loss: 1.5808 - val_acc: 0.4375\n",
      "\n",
      "Epoch 192/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 100us/step - loss: 1.6686 - acc: 0.3843 - val_loss: 1.5732 - val_acc: 0.4583\n",
      "\n",
      "Epoch 193/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 78us/step - loss: 1.7097 - acc: 0.3796 - val_loss: 1.5740 - val_acc: 0.4375\n",
      "\n",
      "Epoch 194/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 101us/step - loss: 1.6711 - acc: 0.3611 - val_loss: 1.5705 - val_acc: 0.4583\n",
      "\n",
      "Epoch 195/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 92us/step - loss: 1.7349 - acc: 0.3611 - val_loss: 1.5805 - val_acc: 0.4583\n",
      "\n",
      "Epoch 196/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 103us/step - loss: 1.6622 - acc: 0.4074 - val_loss: 1.5884 - val_acc: 0.4375\n",
      "\n",
      "Epoch 197/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 85us/step - loss: 1.6236 - acc: 0.4352 - val_loss: 1.5727 - val_acc: 0.4583\n",
      "\n",
      "Epoch 198/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 97us/step - loss: 1.6565 - acc: 0.3889 - val_loss: 1.5825 - val_acc: 0.4375\n",
      "\n",
      "Epoch 199/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 89us/step - loss: 1.7019 - acc: 0.3750 - val_loss: 1.5873 - val_acc: 0.4375\n",
      "\n",
      "Epoch 200/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 83us/step - loss: 1.6030 - acc: 0.4120 - val_loss: 1.5697 - val_acc: 0.4583\n",
      "\n",
      "Epoch 201/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 99us/step - loss: 1.6931 - acc: 0.3611 - val_loss: 1.5756 - val_acc: 0.4583\n",
      "\n",
      "Epoch 202/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 84us/step - loss: 1.6020 - acc: 0.4120 - val_loss: 1.5797 - val_acc: 0.4375\n",
      "\n",
      "Epoch 203/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 81us/step - loss: 1.6548 - acc: 0.4074 - val_loss: 1.5810 - val_acc: 0.4375\n",
      "\n",
      "Epoch 204/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 77us/step - loss: 1.6262 - acc: 0.4259 - val_loss: 1.5813 - val_acc: 0.4375\n",
      "\n",
      "Epoch 205/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 94us/step - loss: 1.6781 - acc: 0.3519 - val_loss: 1.5720 - val_acc: 0.4375\n",
      "\n",
      "Epoch 206/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 95us/step - loss: 1.6485 - acc: 0.4120 - val_loss: 1.5840 - val_acc: 0.4375\n",
      "\n",
      "Epoch 207/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 100us/step - loss: 1.6534 - acc: 0.3565 - val_loss: 1.5858 - val_acc: 0.4375\n",
      "\n",
      "Epoch 208/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 76us/step - loss: 1.6426 - acc: 0.3935 - val_loss: 1.5948 - val_acc: 0.4375\n",
      "\n",
      "Epoch 209/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 98us/step - loss: 1.7042 - acc: 0.3519 - val_loss: 1.5862 - val_acc: 0.4375\n",
      "\n",
      "Epoch 210/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 92us/step - loss: 1.6051 - acc: 0.4167 - val_loss: 1.5880 - val_acc: 0.4375\n",
      "\n",
      "Epoch 211/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 93us/step - loss: 1.6728 - acc: 0.3426 - val_loss: 1.5853 - val_acc: 0.4375\n",
      "\n",
      "Epoch 212/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 86us/step - loss: 1.5777 - acc: 0.3935 - val_loss: 1.5851 - val_acc: 0.4375\n",
      "\n",
      "Epoch 213/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 93us/step - loss: 1.6466 - acc: 0.3657 - val_loss: 1.5773 - val_acc: 0.4583\n",
      "\n",
      "Epoch 214/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 100us/step - loss: 1.6451 - acc: 0.3611 - val_loss: 1.5783 - val_acc: 0.4375\n",
      "\n",
      "Epoch 215/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 99us/step - loss: 1.6522 - acc: 0.4120 - val_loss: 1.5754 - val_acc: 0.4583\n",
      "\n",
      "Epoch 216/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 43us/step - loss: 1.6392 - acc: 0.3889 - val_loss: 1.5735 - val_acc: 0.4583\n",
      "\n",
      "Epoch 217/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 43us/step - loss: 1.7081 - acc: 0.4028 - val_loss: 1.5708 - val_acc: 0.4375\n",
      "\n",
      "Epoch 218/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 37us/step - loss: 1.6064 - acc: 0.4398 - val_loss: 1.5839 - val_acc: 0.4375\n",
      "\n",
      "Epoch 219/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 35us/step - loss: 1.5972 - acc: 0.4213 - val_loss: 1.5807 - val_acc: 0.4375\n",
      "\n",
      "Epoch 220/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 37us/step - loss: 1.5799 - acc: 0.3889 - val_loss: 1.5789 - val_acc: 0.4583\n",
      "\n",
      "Epoch 221/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 34us/step - loss: 1.6187 - acc: 0.4120 - val_loss: 1.5856 - val_acc: 0.4375\n",
      "\n",
      "Epoch 222/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 32us/step - loss: 1.6594 - acc: 0.4120 - val_loss: 1.5905 - val_acc: 0.4375\n",
      "\n",
      "Epoch 223/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 34us/step - loss: 1.7038 - acc: 0.3750 - val_loss: 1.5860 - val_acc: 0.4583\n",
      "\n",
      "Epoch 224/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 33us/step - loss: 1.6641 - acc: 0.3704 - val_loss: 1.5863 - val_acc: 0.4375\n",
      "\n",
      "Epoch 225/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 34us/step - loss: 1.6264 - acc: 0.4259 - val_loss: 1.5799 - val_acc: 0.4375\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 226/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 64us/step - loss: 1.5902 - acc: 0.4306 - val_loss: 1.5664 - val_acc: 0.4583\n",
      "\n",
      "Epoch 227/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 34us/step - loss: 1.6315 - acc: 0.4352 - val_loss: 1.5688 - val_acc: 0.4583\n",
      "\n",
      "Epoch 228/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 34us/step - loss: 1.7018 - acc: 0.4074 - val_loss: 1.5710 - val_acc: 0.4583\n",
      "\n",
      "Epoch 229/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 36us/step - loss: 1.6596 - acc: 0.4213 - val_loss: 1.5805 - val_acc: 0.4375\n",
      "\n",
      "Epoch 230/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 35us/step - loss: 1.6792 - acc: 0.3750 - val_loss: 1.5800 - val_acc: 0.4583\n",
      "\n",
      "Epoch 231/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 37us/step - loss: 1.6250 - acc: 0.4167 - val_loss: 1.5755 - val_acc: 0.4583\n",
      "\n",
      "Epoch 232/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 42us/step - loss: 1.5864 - acc: 0.4259 - val_loss: 1.5852 - val_acc: 0.4375\n",
      "\n",
      "Epoch 233/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 37us/step - loss: 1.6146 - acc: 0.3750 - val_loss: 1.5722 - val_acc: 0.4583\n",
      "\n",
      "Epoch 234/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 39us/step - loss: 1.6062 - acc: 0.4074 - val_loss: 1.5637 - val_acc: 0.4583\n",
      "\n",
      "Epoch 235/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 34us/step - loss: 1.6973 - acc: 0.3889 - val_loss: 1.5691 - val_acc: 0.4583\n",
      "\n",
      "Epoch 236/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 33us/step - loss: 1.6824 - acc: 0.3981 - val_loss: 1.5698 - val_acc: 0.4792\n",
      "\n",
      "Epoch 237/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 35us/step - loss: 1.6208 - acc: 0.4074 - val_loss: 1.5704 - val_acc: 0.4792\n",
      "\n",
      "Epoch 238/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 34us/step - loss: 1.6426 - acc: 0.3472 - val_loss: 1.5706 - val_acc: 0.4792\n",
      "\n",
      "Epoch 239/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 39us/step - loss: 1.6330 - acc: 0.4120 - val_loss: 1.5778 - val_acc: 0.4583\n",
      "\n",
      "Epoch 240/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 33us/step - loss: 1.6511 - acc: 0.3704 - val_loss: 1.5763 - val_acc: 0.4792\n",
      "\n",
      "Epoch 241/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 39us/step - loss: 1.6012 - acc: 0.3750 - val_loss: 1.5672 - val_acc: 0.4792\n",
      "\n",
      "Epoch 242/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 36us/step - loss: 1.6716 - acc: 0.3796 - val_loss: 1.5607 - val_acc: 0.4792\n",
      "\n",
      "Epoch 243/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 39us/step - loss: 1.6734 - acc: 0.3889 - val_loss: 1.5639 - val_acc: 0.4792\n",
      "\n",
      "Epoch 244/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 35us/step - loss: 1.6586 - acc: 0.3981 - val_loss: 1.5637 - val_acc: 0.4583\n",
      "\n",
      "Epoch 245/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 34us/step - loss: 1.6043 - acc: 0.4120 - val_loss: 1.5684 - val_acc: 0.4792\n",
      "\n",
      "Epoch 246/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 37us/step - loss: 1.6181 - acc: 0.4259 - val_loss: 1.5794 - val_acc: 0.4583\n",
      "\n",
      "Epoch 247/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 58us/step - loss: 1.5651 - acc: 0.4306 - val_loss: 1.5721 - val_acc: 0.4792\n",
      "\n",
      "Epoch 248/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 36us/step - loss: 1.6972 - acc: 0.3426 - val_loss: 1.5695 - val_acc: 0.4583\n",
      "\n",
      "Epoch 249/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 35us/step - loss: 1.5761 - acc: 0.4722 - val_loss: 1.5694 - val_acc: 0.4583\n",
      "\n",
      "Epoch 250/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 43us/step - loss: 1.5890 - acc: 0.4398 - val_loss: 1.5607 - val_acc: 0.4583\n",
      "\n",
      "Epoch 251/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 35us/step - loss: 1.6427 - acc: 0.3935 - val_loss: 1.5570 - val_acc: 0.4792\n",
      "\n",
      "Epoch 252/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 39us/step - loss: 1.6075 - acc: 0.4167 - val_loss: 1.5518 - val_acc: 0.5000\n",
      "\n",
      "Epoch 253/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 34us/step - loss: 1.6419 - acc: 0.3843 - val_loss: 1.5501 - val_acc: 0.5000\n",
      "\n",
      "Epoch 254/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 33us/step - loss: 1.7135 - acc: 0.3287 - val_loss: 1.5521 - val_acc: 0.4792\n",
      "\n",
      "Epoch 255/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 32us/step - loss: 1.5861 - acc: 0.4167 - val_loss: 1.5472 - val_acc: 0.4792\n",
      "\n",
      "Epoch 256/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 37us/step - loss: 1.5809 - acc: 0.4167 - val_loss: 1.5556 - val_acc: 0.4792\n",
      "\n",
      "Epoch 257/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 39us/step - loss: 1.5142 - acc: 0.4630 - val_loss: 1.5678 - val_acc: 0.4583\n",
      "\n",
      "Epoch 258/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 33us/step - loss: 1.6246 - acc: 0.4028 - val_loss: 1.5751 - val_acc: 0.4792\n",
      "\n",
      "Epoch 259/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 36us/step - loss: 1.5957 - acc: 0.3796 - val_loss: 1.5688 - val_acc: 0.4583\n",
      "\n",
      "Epoch 260/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 33us/step - loss: 1.6751 - acc: 0.3889 - val_loss: 1.5720 - val_acc: 0.4792\n",
      "\n",
      "Epoch 261/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 34us/step - loss: 1.5725 - acc: 0.4167 - val_loss: 1.5742 - val_acc: 0.4583\n",
      "\n",
      "Epoch 262/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 37us/step - loss: 1.5109 - acc: 0.4769 - val_loss: 1.5561 - val_acc: 0.4583\n",
      "\n",
      "Epoch 263/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 57us/step - loss: 1.6073 - acc: 0.4120 - val_loss: 1.5542 - val_acc: 0.4792\n",
      "\n",
      "Epoch 264/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 38us/step - loss: 1.5755 - acc: 0.4213 - val_loss: 1.5573 - val_acc: 0.4583\n",
      "\n",
      "Epoch 265/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 35us/step - loss: 1.6235 - acc: 0.3750 - val_loss: 1.5643 - val_acc: 0.4792\n",
      "\n",
      "Epoch 266/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 32us/step - loss: 1.6136 - acc: 0.3843 - val_loss: 1.5668 - val_acc: 0.4792\n",
      "\n",
      "Epoch 267/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 49us/step - loss: 1.6684 - acc: 0.3426 - val_loss: 1.5643 - val_acc: 0.4792\n",
      "\n",
      "Epoch 268/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 47us/step - loss: 1.6103 - acc: 0.3935 - val_loss: 1.5628 - val_acc: 0.4792\n",
      "\n",
      "Epoch 269/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 41us/step - loss: 1.5905 - acc: 0.3843 - val_loss: 1.5688 - val_acc: 0.4792\n",
      "\n",
      "Epoch 270/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 38us/step - loss: 1.5904 - acc: 0.4213 - val_loss: 1.5628 - val_acc: 0.4792\n",
      "\n",
      "Epoch 271/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 42us/step - loss: 1.6009 - acc: 0.4167 - val_loss: 1.5533 - val_acc: 0.4792\n",
      "\n",
      "Epoch 272/1200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "216/216 [==============================]216/216 [==============================] - 0s 51us/step - loss: 1.5428 - acc: 0.4398 - val_loss: 1.5530 - val_acc: 0.5000\n",
      "\n",
      "Epoch 273/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 59us/step - loss: 1.5665 - acc: 0.4444 - val_loss: 1.5617 - val_acc: 0.5000\n",
      "\n",
      "Epoch 274/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 112us/step - loss: 1.6511 - acc: 0.3843 - val_loss: 1.5540 - val_acc: 0.5000\n",
      "\n",
      "Epoch 275/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 147us/step - loss: 1.4774 - acc: 0.4630 - val_loss: 1.5499 - val_acc: 0.4792\n",
      "\n",
      "Epoch 276/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 180us/step - loss: 1.4935 - acc: 0.4398 - val_loss: 1.5487 - val_acc: 0.4792\n",
      "\n",
      "Epoch 277/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 125us/step - loss: 1.5744 - acc: 0.4074 - val_loss: 1.5489 - val_acc: 0.4792\n",
      "\n",
      "Epoch 278/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 118us/step - loss: 1.6546 - acc: 0.3519 - val_loss: 1.5556 - val_acc: 0.5000\n",
      "\n",
      "Epoch 279/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 119us/step - loss: 1.6190 - acc: 0.3981 - val_loss: 1.5610 - val_acc: 0.5000\n",
      "\n",
      "Epoch 280/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 105us/step - loss: 1.5531 - acc: 0.4074 - val_loss: 1.5582 - val_acc: 0.5000\n",
      "\n",
      "Epoch 281/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 123us/step - loss: 1.5686 - acc: 0.3843 - val_loss: 1.5594 - val_acc: 0.5000\n",
      "\n",
      "Epoch 282/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 103us/step - loss: 1.5994 - acc: 0.3796 - val_loss: 1.5606 - val_acc: 0.5000\n",
      "\n",
      "Epoch 283/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 101us/step - loss: 1.6431 - acc: 0.3611 - val_loss: 1.5543 - val_acc: 0.5000\n",
      "\n",
      "Epoch 284/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 111us/step - loss: 1.6262 - acc: 0.4167 - val_loss: 1.5538 - val_acc: 0.5000\n",
      "\n",
      "Epoch 285/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 105us/step - loss: 1.5508 - acc: 0.4167 - val_loss: 1.5560 - val_acc: 0.5000\n",
      "\n",
      "Epoch 286/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 101us/step - loss: 1.4695 - acc: 0.4815 - val_loss: 1.5496 - val_acc: 0.5000\n",
      "\n",
      "Epoch 287/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 105us/step - loss: 1.5510 - acc: 0.4491 - val_loss: 1.5583 - val_acc: 0.5000\n",
      "\n",
      "Epoch 288/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 223us/step - loss: 1.5298 - acc: 0.4444 - val_loss: 1.5560 - val_acc: 0.5000\n",
      "\n",
      "Epoch 289/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 109us/step - loss: 1.6706 - acc: 0.3472 - val_loss: 1.5594 - val_acc: 0.5000\n",
      "\n",
      "Epoch 290/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 110us/step - loss: 1.5973 - acc: 0.3750 - val_loss: 1.5526 - val_acc: 0.5000\n",
      "\n",
      "Epoch 291/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 109us/step - loss: 1.5550 - acc: 0.4537 - val_loss: 1.5526 - val_acc: 0.5000\n",
      "\n",
      "Epoch 292/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 99us/step - loss: 1.5979 - acc: 0.4259 - val_loss: 1.5485 - val_acc: 0.5000\n",
      "\n",
      "Epoch 293/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 138us/step - loss: 1.5687 - acc: 0.3981 - val_loss: 1.5476 - val_acc: 0.5000\n",
      "\n",
      "Epoch 294/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 106us/step - loss: 1.5824 - acc: 0.3611 - val_loss: 1.5604 - val_acc: 0.5000\n",
      "\n",
      "Epoch 295/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 101us/step - loss: 1.5238 - acc: 0.4815 - val_loss: 1.5620 - val_acc: 0.5000\n",
      "\n",
      "Epoch 296/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 108us/step - loss: 1.5941 - acc: 0.3981 - val_loss: 1.5514 - val_acc: 0.5000\n",
      "\n",
      "Epoch 297/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 108us/step - loss: 1.5576 - acc: 0.4306 - val_loss: 1.5453 - val_acc: 0.5000\n",
      "\n",
      "Epoch 298/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 122us/step - loss: 1.5683 - acc: 0.4352 - val_loss: 1.5539 - val_acc: 0.5000\n",
      "\n",
      "Epoch 299/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 99us/step - loss: 1.6019 - acc: 0.4120 - val_loss: 1.5544 - val_acc: 0.5000\n",
      "\n",
      "Epoch 300/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 84us/step - loss: 1.5880 - acc: 0.4259 - val_loss: 1.5573 - val_acc: 0.5000\n",
      "\n",
      "Epoch 301/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 93us/step - loss: 1.5408 - acc: 0.4352 - val_loss: 1.5561 - val_acc: 0.5000\n",
      "\n",
      "Epoch 302/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 82us/step - loss: 1.5591 - acc: 0.4537 - val_loss: 1.5568 - val_acc: 0.5000\n",
      "\n",
      "Epoch 303/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 102us/step - loss: 1.5548 - acc: 0.3981 - val_loss: 1.5570 - val_acc: 0.5000\n",
      "\n",
      "Epoch 304/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 86us/step - loss: 1.6209 - acc: 0.3889 - val_loss: 1.5556 - val_acc: 0.5000\n",
      "\n",
      "Epoch 305/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 92us/step - loss: 1.5662 - acc: 0.3981 - val_loss: 1.5642 - val_acc: 0.5000\n",
      "\n",
      "Epoch 306/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 103us/step - loss: 1.5898 - acc: 0.4120 - val_loss: 1.5636 - val_acc: 0.5000\n",
      "\n",
      "Epoch 307/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 108us/step - loss: 1.5656 - acc: 0.4074 - val_loss: 1.5746 - val_acc: 0.4792\n",
      "\n",
      "Epoch 308/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 100us/step - loss: 1.5828 - acc: 0.3981 - val_loss: 1.5715 - val_acc: 0.4792\n",
      "\n",
      "Epoch 309/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 88us/step - loss: 1.5556 - acc: 0.4583 - val_loss: 1.5690 - val_acc: 0.4792\n",
      "\n",
      "Epoch 310/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 107us/step - loss: 1.6214 - acc: 0.3565 - val_loss: 1.5626 - val_acc: 0.4792\n",
      "\n",
      "Epoch 311/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 98us/step - loss: 1.5151 - acc: 0.4444 - val_loss: 1.5588 - val_acc: 0.5208\n",
      "\n",
      "Epoch 312/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 114us/step - loss: 1.4838 - acc: 0.4259 - val_loss: 1.5545 - val_acc: 0.5000\n",
      "\n",
      "Epoch 313/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 82us/step - loss: 1.5463 - acc: 0.4213 - val_loss: 1.5446 - val_acc: 0.5000\n",
      "\n",
      "Epoch 314/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 85us/step - loss: 1.6139 - acc: 0.3843 - val_loss: 1.5494 - val_acc: 0.5208\n",
      "\n",
      "Epoch 315/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 88us/step - loss: 1.5168 - acc: 0.4120 - val_loss: 1.5572 - val_acc: 0.5208\n",
      "\n",
      "Epoch 316/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 90us/step - loss: 1.6065 - acc: 0.4120 - val_loss: 1.5549 - val_acc: 0.5000\n",
      "\n",
      "Epoch 317/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 98us/step - loss: 1.5294 - acc: 0.4213 - val_loss: 1.5591 - val_acc: 0.5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 318/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 88us/step - loss: 1.5787 - acc: 0.4444 - val_loss: 1.5509 - val_acc: 0.5000\n",
      "\n",
      "Epoch 319/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 92us/step - loss: 1.5327 - acc: 0.4259 - val_loss: 1.5416 - val_acc: 0.4792\n",
      "\n",
      "Epoch 320/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 88us/step - loss: 1.6293 - acc: 0.3287 - val_loss: 1.5561 - val_acc: 0.5000\n",
      "\n",
      "Epoch 321/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 95us/step - loss: 1.5906 - acc: 0.3889 - val_loss: 1.5682 - val_acc: 0.5000\n",
      "\n",
      "Epoch 322/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 91us/step - loss: 1.5909 - acc: 0.3935 - val_loss: 1.5682 - val_acc: 0.5000\n",
      "\n",
      "Epoch 323/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 82us/step - loss: 1.5608 - acc: 0.3889 - val_loss: 1.5510 - val_acc: 0.5000\n",
      "\n",
      "Epoch 324/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 90us/step - loss: 1.6169 - acc: 0.4028 - val_loss: 1.5560 - val_acc: 0.5000\n",
      "\n",
      "Epoch 325/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 82us/step - loss: 1.5534 - acc: 0.4167 - val_loss: 1.5541 - val_acc: 0.5208\n",
      "\n",
      "Epoch 326/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 91us/step - loss: 1.5146 - acc: 0.4120 - val_loss: 1.5513 - val_acc: 0.5000\n",
      "\n",
      "Epoch 327/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 40us/step - loss: 1.5078 - acc: 0.4583 - val_loss: 1.5467 - val_acc: 0.5000\n",
      "\n",
      "Epoch 328/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 34us/step - loss: 1.5466 - acc: 0.4028 - val_loss: 1.5469 - val_acc: 0.5000\n",
      "\n",
      "Epoch 329/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 35us/step - loss: 1.4544 - acc: 0.4954 - val_loss: 1.5485 - val_acc: 0.5000\n",
      "\n",
      "Epoch 330/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 35us/step - loss: 1.4493 - acc: 0.4444 - val_loss: 1.5373 - val_acc: 0.5000\n",
      "\n",
      "Epoch 331/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 33us/step - loss: 1.5703 - acc: 0.4306 - val_loss: 1.5443 - val_acc: 0.5000\n",
      "\n",
      "Epoch 332/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 65us/step - loss: 1.5286 - acc: 0.4352 - val_loss: 1.5528 - val_acc: 0.5000\n",
      "\n",
      "Epoch 333/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 32us/step - loss: 1.5434 - acc: 0.4306 - val_loss: 1.5576 - val_acc: 0.5000\n",
      "\n",
      "Epoch 334/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 32us/step - loss: 1.5148 - acc: 0.4352 - val_loss: 1.5521 - val_acc: 0.5000\n",
      "\n",
      "Epoch 335/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 33us/step - loss: 1.5461 - acc: 0.4491 - val_loss: 1.5571 - val_acc: 0.5000\n",
      "\n",
      "Epoch 336/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 30us/step - loss: 1.5563 - acc: 0.4167 - val_loss: 1.5619 - val_acc: 0.5000\n",
      "\n",
      "Epoch 337/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 38us/step - loss: 1.5643 - acc: 0.3981 - val_loss: 1.5501 - val_acc: 0.5000\n",
      "\n",
      "Epoch 338/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 35us/step - loss: 1.5485 - acc: 0.4306 - val_loss: 1.5492 - val_acc: 0.5417\n",
      "\n",
      "Epoch 339/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 33us/step - loss: 1.5405 - acc: 0.4120 - val_loss: 1.5477 - val_acc: 0.5208\n",
      "\n",
      "Epoch 340/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 32us/step - loss: 1.5142 - acc: 0.4167 - val_loss: 1.5569 - val_acc: 0.5208\n",
      "\n",
      "Epoch 341/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 41us/step - loss: 1.5521 - acc: 0.4352 - val_loss: 1.5501 - val_acc: 0.5000\n",
      "\n",
      "Epoch 342/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 32us/step - loss: 1.5947 - acc: 0.3889 - val_loss: 1.5529 - val_acc: 0.5000\n",
      "\n",
      "Epoch 343/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 37us/step - loss: 1.5734 - acc: 0.4028 - val_loss: 1.5535 - val_acc: 0.5000\n",
      "\n",
      "Epoch 344/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 36us/step - loss: 1.5484 - acc: 0.3843 - val_loss: 1.5595 - val_acc: 0.5000\n",
      "\n",
      "Epoch 345/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 33us/step - loss: 1.5938 - acc: 0.4074 - val_loss: 1.5648 - val_acc: 0.5208\n",
      "\n",
      "Epoch 346/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 32us/step - loss: 1.5400 - acc: 0.3889 - val_loss: 1.5576 - val_acc: 0.5000\n",
      "\n",
      "Epoch 347/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 34us/step - loss: 1.5846 - acc: 0.4398 - val_loss: 1.5541 - val_acc: 0.5208\n",
      "\n",
      "Epoch 348/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 31us/step - loss: 1.4724 - acc: 0.4537 - val_loss: 1.5480 - val_acc: 0.5000\n",
      "\n",
      "Epoch 349/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 33us/step - loss: 1.6145 - acc: 0.3519 - val_loss: 1.5511 - val_acc: 0.5000\n",
      "\n",
      "Epoch 350/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 32us/step - loss: 1.5053 - acc: 0.4306 - val_loss: 1.5563 - val_acc: 0.5208\n",
      "\n",
      "Epoch 351/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 35us/step - loss: 1.5138 - acc: 0.4630 - val_loss: 1.5556 - val_acc: 0.5208\n",
      "\n",
      "Epoch 352/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 32us/step - loss: 1.5938 - acc: 0.3981 - val_loss: 1.5623 - val_acc: 0.5000\n",
      "\n",
      "Epoch 353/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 34us/step - loss: 1.5198 - acc: 0.4352 - val_loss: 1.5604 - val_acc: 0.5000\n",
      "\n",
      "Epoch 354/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 31us/step - loss: 1.5739 - acc: 0.3565 - val_loss: 1.5662 - val_acc: 0.5208\n",
      "\n",
      "Epoch 355/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 33us/step - loss: 1.4508 - acc: 0.4954 - val_loss: 1.5668 - val_acc: 0.5208\n",
      "\n",
      "Epoch 356/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 33us/step - loss: 1.5306 - acc: 0.4259 - val_loss: 1.5640 - val_acc: 0.5000\n",
      "\n",
      "Epoch 357/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 34us/step - loss: 1.5176 - acc: 0.4398 - val_loss: 1.5721 - val_acc: 0.5417\n",
      "\n",
      "Epoch 358/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 33us/step - loss: 1.4908 - acc: 0.4352 - val_loss: 1.5655 - val_acc: 0.5417\n",
      "\n",
      "Epoch 359/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 35us/step - loss: 1.5528 - acc: 0.4259 - val_loss: 1.5585 - val_acc: 0.5417\n",
      "\n",
      "Epoch 360/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 31us/step - loss: 1.5473 - acc: 0.4398 - val_loss: 1.5589 - val_acc: 0.5208\n",
      "\n",
      "Epoch 361/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 32us/step - loss: 1.4951 - acc: 0.4444 - val_loss: 1.5510 - val_acc: 0.5208\n",
      "\n",
      "Epoch 362/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 31us/step - loss: 1.5045 - acc: 0.4537 - val_loss: 1.5596 - val_acc: 0.5417\n",
      "\n",
      "Epoch 363/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 33us/step - loss: 1.5781 - acc: 0.3935 - val_loss: 1.5699 - val_acc: 0.5417\n",
      "\n",
      "Epoch 364/1200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "216/216 [==============================]216/216 [==============================] - 0s 35us/step - loss: 1.4853 - acc: 0.4537 - val_loss: 1.5604 - val_acc: 0.5208\n",
      "\n",
      "Epoch 365/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 34us/step - loss: 1.4778 - acc: 0.4259 - val_loss: 1.5621 - val_acc: 0.5208\n",
      "\n",
      "Epoch 366/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 32us/step - loss: 1.5500 - acc: 0.3704 - val_loss: 1.5674 - val_acc: 0.5208\n",
      "\n",
      "Epoch 367/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 31us/step - loss: 1.5611 - acc: 0.4352 - val_loss: 1.5734 - val_acc: 0.5417\n",
      "\n",
      "Epoch 368/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 30us/step - loss: 1.5309 - acc: 0.4444 - val_loss: 1.5701 - val_acc: 0.5208\n",
      "\n",
      "Epoch 369/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 35us/step - loss: 1.5161 - acc: 0.4954 - val_loss: 1.5726 - val_acc: 0.5000\n",
      "\n",
      "Epoch 370/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 33us/step - loss: 1.5338 - acc: 0.4120 - val_loss: 1.5659 - val_acc: 0.5000\n",
      "\n",
      "Epoch 371/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 33us/step - loss: 1.5925 - acc: 0.3981 - val_loss: 1.5648 - val_acc: 0.5208\n",
      "\n",
      "Epoch 372/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 33us/step - loss: 1.5396 - acc: 0.4074 - val_loss: 1.5670 - val_acc: 0.5208\n",
      "\n",
      "Epoch 373/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 33us/step - loss: 1.5107 - acc: 0.4398 - val_loss: 1.5633 - val_acc: 0.5208\n",
      "\n",
      "Epoch 374/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 32us/step - loss: 1.5734 - acc: 0.3935 - val_loss: 1.5635 - val_acc: 0.5000\n",
      "\n",
      "Epoch 375/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 32us/step - loss: 1.4970 - acc: 0.4352 - val_loss: 1.5652 - val_acc: 0.4792\n",
      "\n",
      "Epoch 376/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 43us/step - loss: 1.5557 - acc: 0.4352 - val_loss: 1.5604 - val_acc: 0.5000\n",
      "\n",
      "Epoch 377/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 34us/step - loss: 1.5205 - acc: 0.4259 - val_loss: 1.5591 - val_acc: 0.5208\n",
      "\n",
      "Epoch 378/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 37us/step - loss: 1.4729 - acc: 0.4537 - val_loss: 1.5592 - val_acc: 0.5208\n",
      "\n",
      "Epoch 379/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 35us/step - loss: 1.4843 - acc: 0.4722 - val_loss: 1.5624 - val_acc: 0.5208\n",
      "\n",
      "Epoch 380/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 32us/step - loss: 1.5425 - acc: 0.4398 - val_loss: 1.5542 - val_acc: 0.5000\n",
      "\n",
      "Epoch 381/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 36us/step - loss: 1.5509 - acc: 0.3843 - val_loss: 1.5523 - val_acc: 0.5208\n",
      "\n",
      "Epoch 382/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 34us/step - loss: 1.5436 - acc: 0.4444 - val_loss: 1.5466 - val_acc: 0.5000\n",
      "\n",
      "Epoch 383/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 34us/step - loss: 1.5434 - acc: 0.4120 - val_loss: 1.5460 - val_acc: 0.5000\n",
      "\n",
      "Epoch 384/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 34us/step - loss: 1.4916 - acc: 0.4352 - val_loss: 1.5491 - val_acc: 0.5208\n",
      "\n",
      "Epoch 385/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 34us/step - loss: 1.5284 - acc: 0.4398 - val_loss: 1.5503 - val_acc: 0.5208\n",
      "\n",
      "Epoch 386/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 31us/step - loss: 1.4626 - acc: 0.4907 - val_loss: 1.5532 - val_acc: 0.5208\n",
      "\n",
      "Epoch 387/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 34us/step - loss: 1.4742 - acc: 0.4722 - val_loss: 1.5519 - val_acc: 0.5208\n",
      "\n",
      "Epoch 388/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 46us/step - loss: 1.5006 - acc: 0.4444 - val_loss: 1.5609 - val_acc: 0.5208\n",
      "\n",
      "Epoch 389/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 44us/step - loss: 1.4846 - acc: 0.4722 - val_loss: 1.5477 - val_acc: 0.5000\n",
      "\n",
      "Epoch 390/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 39us/step - loss: 1.4957 - acc: 0.4306 - val_loss: 1.5603 - val_acc: 0.5000\n",
      "\n",
      "Epoch 391/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 107us/step - loss: 1.5104 - acc: 0.4491 - val_loss: 1.5640 - val_acc: 0.5208\n",
      "\n",
      "Epoch 392/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 108us/step - loss: 1.5194 - acc: 0.4352 - val_loss: 1.5607 - val_acc: 0.5208\n",
      "\n",
      "Epoch 393/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 215us/step - loss: 1.6055 - acc: 0.3889 - val_loss: 1.5661 - val_acc: 0.5208\n",
      "\n",
      "Epoch 394/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 114us/step - loss: 1.5450 - acc: 0.4259 - val_loss: 1.5679 - val_acc: 0.5208\n",
      "\n",
      "Epoch 395/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 109us/step - loss: 1.4533 - acc: 0.4583 - val_loss: 1.5619 - val_acc: 0.5208\n",
      "\n",
      "Epoch 396/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 109us/step - loss: 1.4928 - acc: 0.4074 - val_loss: 1.5584 - val_acc: 0.5208\n",
      "\n",
      "Epoch 397/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 103us/step - loss: 1.5547 - acc: 0.3981 - val_loss: 1.5610 - val_acc: 0.5000\n",
      "\n",
      "Epoch 398/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 114us/step - loss: 1.6113 - acc: 0.3889 - val_loss: 1.5722 - val_acc: 0.5000\n",
      "\n",
      "Epoch 399/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 108us/step - loss: 1.5770 - acc: 0.3565 - val_loss: 1.5623 - val_acc: 0.5417\n",
      "\n",
      "Epoch 400/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 110us/step - loss: 1.4313 - acc: 0.4815 - val_loss: 1.5602 - val_acc: 0.5208\n",
      "\n",
      "Epoch 401/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 99us/step - loss: 1.4309 - acc: 0.5046 - val_loss: 1.5604 - val_acc: 0.5208\n",
      "\n",
      "Epoch 402/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 107us/step - loss: 1.5096 - acc: 0.4352 - val_loss: 1.5558 - val_acc: 0.5208\n",
      "\n",
      "Epoch 403/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 100us/step - loss: 1.5469 - acc: 0.4074 - val_loss: 1.5555 - val_acc: 0.5417\n",
      "\n",
      "Epoch 404/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 106us/step - loss: 1.4000 - acc: 0.4769 - val_loss: 1.5505 - val_acc: 0.5417\n",
      "\n",
      "Epoch 405/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 111us/step - loss: 1.5476 - acc: 0.4167 - val_loss: 1.5495 - val_acc: 0.5417\n",
      "\n",
      "Epoch 406/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 232us/step - loss: 1.5530 - acc: 0.4444 - val_loss: 1.5429 - val_acc: 0.5417\n",
      "\n",
      "Epoch 407/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 111us/step - loss: 1.5069 - acc: 0.4259 - val_loss: 1.5606 - val_acc: 0.5417\n",
      "\n",
      "Epoch 408/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 94us/step - loss: 1.4861 - acc: 0.4352 - val_loss: 1.5526 - val_acc: 0.5208\n",
      "\n",
      "Epoch 409/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 95us/step - loss: 1.5054 - acc: 0.4815 - val_loss: 1.5527 - val_acc: 0.5417\n",
      "\n",
      "Epoch 410/1200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "216/216 [==============================]216/216 [==============================] - 0s 101us/step - loss: 1.5264 - acc: 0.4537 - val_loss: 1.5584 - val_acc: 0.5417\n",
      "\n",
      "Epoch 411/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 135us/step - loss: 1.5408 - acc: 0.4120 - val_loss: 1.5638 - val_acc: 0.5625\n",
      "\n",
      "Epoch 412/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 107us/step - loss: 1.4987 - acc: 0.4815 - val_loss: 1.5628 - val_acc: 0.5625\n",
      "\n",
      "Epoch 413/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 100us/step - loss: 1.5281 - acc: 0.3935 - val_loss: 1.5572 - val_acc: 0.5417\n",
      "\n",
      "Epoch 414/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 111us/step - loss: 1.4330 - acc: 0.4676 - val_loss: 1.5625 - val_acc: 0.5417\n",
      "\n",
      "Epoch 415/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 95us/step - loss: 1.4907 - acc: 0.4444 - val_loss: 1.5618 - val_acc: 0.5208\n",
      "\n",
      "Epoch 416/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 147us/step - loss: 1.4993 - acc: 0.4583 - val_loss: 1.5589 - val_acc: 0.5208\n",
      "\n",
      "Epoch 417/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 97us/step - loss: 1.4797 - acc: 0.4861 - val_loss: 1.5553 - val_acc: 0.5208\n",
      "\n",
      "Epoch 418/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 90us/step - loss: 1.5034 - acc: 0.4167 - val_loss: 1.5624 - val_acc: 0.5208\n",
      "\n",
      "Epoch 419/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 86us/step - loss: 1.4934 - acc: 0.4444 - val_loss: 1.5558 - val_acc: 0.5208\n",
      "\n",
      "Epoch 420/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 108us/step - loss: 1.4886 - acc: 0.4630 - val_loss: 1.5581 - val_acc: 0.5208\n",
      "\n",
      "Epoch 421/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 102us/step - loss: 1.5111 - acc: 0.3935 - val_loss: 1.5528 - val_acc: 0.5208\n",
      "\n",
      "Epoch 422/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 105us/step - loss: 1.4661 - acc: 0.4444 - val_loss: 1.5633 - val_acc: 0.5417\n",
      "\n",
      "Epoch 423/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 96us/step - loss: 1.4911 - acc: 0.4306 - val_loss: 1.5685 - val_acc: 0.5417\n",
      "\n",
      "Epoch 424/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 91us/step - loss: 1.4260 - acc: 0.4907 - val_loss: 1.5718 - val_acc: 0.5208\n",
      "\n",
      "Epoch 425/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 96us/step - loss: 1.4826 - acc: 0.4676 - val_loss: 1.5813 - val_acc: 0.5417\n",
      "\n",
      "Epoch 426/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 82us/step - loss: 1.4742 - acc: 0.4074 - val_loss: 1.5698 - val_acc: 0.5417\n",
      "\n",
      "Epoch 427/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 87us/step - loss: 1.5050 - acc: 0.4213 - val_loss: 1.5579 - val_acc: 0.5625\n",
      "\n",
      "Epoch 428/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 101us/step - loss: 1.5087 - acc: 0.4722 - val_loss: 1.5543 - val_acc: 0.5417\n",
      "\n",
      "Epoch 429/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 97us/step - loss: 1.4463 - acc: 0.4444 - val_loss: 1.5550 - val_acc: 0.5417\n",
      "\n",
      "Epoch 430/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 110us/step - loss: 1.5055 - acc: 0.4676 - val_loss: 1.5647 - val_acc: 0.5417\n",
      "\n",
      "Epoch 431/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 93us/step - loss: 1.5172 - acc: 0.4167 - val_loss: 1.5692 - val_acc: 0.5417\n",
      "\n",
      "Epoch 432/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 80us/step - loss: 1.5036 - acc: 0.4259 - val_loss: 1.5715 - val_acc: 0.5417\n",
      "\n",
      "Epoch 433/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 90us/step - loss: 1.5625 - acc: 0.4120 - val_loss: 1.5659 - val_acc: 0.5417\n",
      "\n",
      "Epoch 434/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 82us/step - loss: 1.4750 - acc: 0.4398 - val_loss: 1.5683 - val_acc: 0.5208\n",
      "\n",
      "Epoch 435/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 95us/step - loss: 1.4896 - acc: 0.4676 - val_loss: 1.5750 - val_acc: 0.5417\n",
      "\n",
      "Epoch 436/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 87us/step - loss: 1.4742 - acc: 0.4352 - val_loss: 1.5714 - val_acc: 0.5417\n",
      "\n",
      "Epoch 437/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 112us/step - loss: 1.4728 - acc: 0.4444 - val_loss: 1.5701 - val_acc: 0.5417\n",
      "\n",
      "Epoch 438/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 95us/step - loss: 1.4182 - acc: 0.4769 - val_loss: 1.5684 - val_acc: 0.5417\n",
      "\n",
      "Epoch 439/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 83us/step - loss: 1.4783 - acc: 0.4537 - val_loss: 1.5718 - val_acc: 0.5417\n",
      "\n",
      "Epoch 440/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 81us/step - loss: 1.4245 - acc: 0.4815 - val_loss: 1.5785 - val_acc: 0.5208\n",
      "\n",
      "Epoch 441/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 94us/step - loss: 1.4631 - acc: 0.4954 - val_loss: 1.5767 - val_acc: 0.5000\n",
      "\n",
      "Epoch 442/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 96us/step - loss: 1.4918 - acc: 0.4398 - val_loss: 1.5772 - val_acc: 0.5000\n",
      "\n",
      "Epoch 443/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 101us/step - loss: 1.3851 - acc: 0.4722 - val_loss: 1.5752 - val_acc: 0.5000\n",
      "\n",
      "Epoch 444/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 47us/step - loss: 1.5351 - acc: 0.3889 - val_loss: 1.5738 - val_acc: 0.5208\n",
      "\n",
      "Epoch 445/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 40us/step - loss: 1.4792 - acc: 0.4722 - val_loss: 1.5807 - val_acc: 0.5000\n",
      "\n",
      "Epoch 446/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 39us/step - loss: 1.4733 - acc: 0.4444 - val_loss: 1.5741 - val_acc: 0.5000\n",
      "\n",
      "Epoch 447/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 33us/step - loss: 1.4656 - acc: 0.4213 - val_loss: 1.5755 - val_acc: 0.5417\n",
      "\n",
      "Epoch 448/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 33us/step - loss: 1.4424 - acc: 0.4491 - val_loss: 1.5733 - val_acc: 0.5208\n",
      "\n",
      "Epoch 449/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 31us/step - loss: 1.5695 - acc: 0.4120 - val_loss: 1.5814 - val_acc: 0.5208\n",
      "\n",
      "Epoch 450/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 32us/step - loss: 1.4643 - acc: 0.4583 - val_loss: 1.5802 - val_acc: 0.5208\n",
      "\n",
      "Epoch 451/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 32us/step - loss: 1.5474 - acc: 0.4306 - val_loss: 1.5784 - val_acc: 0.5208\n",
      "\n",
      "Epoch 452/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 34us/step - loss: 1.4869 - acc: 0.4491 - val_loss: 1.5800 - val_acc: 0.5208\n",
      "\n",
      "Epoch 453/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 32us/step - loss: 1.4616 - acc: 0.4537 - val_loss: 1.5840 - val_acc: 0.5208\n",
      "\n",
      "Epoch 454/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 31us/step - loss: 1.5113 - acc: 0.4074 - val_loss: 1.5740 - val_acc: 0.5417\n",
      "\n",
      "Epoch 455/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 33us/step - loss: 1.4395 - acc: 0.4861 - val_loss: 1.5725 - val_acc: 0.5208\n",
      "\n",
      "Epoch 456/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 32us/step - loss: 1.4874 - acc: 0.4722 - val_loss: 1.5702 - val_acc: 0.5417\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 457/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 36us/step - loss: 1.4648 - acc: 0.4352 - val_loss: 1.5719 - val_acc: 0.5000\n",
      "\n",
      "Epoch 458/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 33us/step - loss: 1.4258 - acc: 0.4722 - val_loss: 1.5750 - val_acc: 0.5000\n",
      "\n",
      "Epoch 459/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 37us/step - loss: 1.4750 - acc: 0.4630 - val_loss: 1.5795 - val_acc: 0.5208\n",
      "\n",
      "Epoch 460/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 71us/step - loss: 1.4296 - acc: 0.4769 - val_loss: 1.5864 - val_acc: 0.5000\n",
      "\n",
      "Epoch 461/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 35us/step - loss: 1.5454 - acc: 0.4306 - val_loss: 1.5815 - val_acc: 0.5208\n",
      "\n",
      "Epoch 462/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 33us/step - loss: 1.4782 - acc: 0.4398 - val_loss: 1.5770 - val_acc: 0.5208\n",
      "\n",
      "Epoch 463/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 46us/step - loss: 1.4456 - acc: 0.4583 - val_loss: 1.5835 - val_acc: 0.5208\n",
      "\n",
      "Epoch 464/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 37us/step - loss: 1.5207 - acc: 0.4028 - val_loss: 1.5893 - val_acc: 0.5208\n",
      "\n",
      "Epoch 465/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 33us/step - loss: 1.5812 - acc: 0.4259 - val_loss: 1.5839 - val_acc: 0.5208\n",
      "\n",
      "Epoch 466/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 36us/step - loss: 1.4424 - acc: 0.4583 - val_loss: 1.5869 - val_acc: 0.5208\n",
      "\n",
      "Epoch 467/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 32us/step - loss: 1.4893 - acc: 0.4583 - val_loss: 1.5842 - val_acc: 0.5417\n",
      "\n",
      "Epoch 468/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 34us/step - loss: 1.4392 - acc: 0.4583 - val_loss: 1.5789 - val_acc: 0.5417\n",
      "\n",
      "Epoch 469/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 32us/step - loss: 1.4940 - acc: 0.4722 - val_loss: 1.5784 - val_acc: 0.5417\n",
      "\n",
      "Epoch 470/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 32us/step - loss: 1.4763 - acc: 0.4630 - val_loss: 1.5758 - val_acc: 0.5417\n",
      "\n",
      "Epoch 471/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 41us/step - loss: 1.4699 - acc: 0.4213 - val_loss: 1.5874 - val_acc: 0.5000\n",
      "\n",
      "Epoch 472/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 35us/step - loss: 1.4685 - acc: 0.4583 - val_loss: 1.5821 - val_acc: 0.5208\n",
      "\n",
      "Epoch 473/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 34us/step - loss: 1.4403 - acc: 0.5046 - val_loss: 1.5791 - val_acc: 0.5208\n",
      "\n",
      "Epoch 474/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 34us/step - loss: 1.5163 - acc: 0.4352 - val_loss: 1.5777 - val_acc: 0.5208\n",
      "\n",
      "Epoch 475/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 32us/step - loss: 1.4665 - acc: 0.4861 - val_loss: 1.5782 - val_acc: 0.5208\n",
      "\n",
      "Epoch 476/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 31us/step - loss: 1.5217 - acc: 0.4444 - val_loss: 1.5758 - val_acc: 0.5208\n",
      "\n",
      "Epoch 477/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 36us/step - loss: 1.4342 - acc: 0.4815 - val_loss: 1.5773 - val_acc: 0.5208\n",
      "\n",
      "Epoch 478/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 35us/step - loss: 1.3963 - acc: 0.4954 - val_loss: 1.5796 - val_acc: 0.5208\n",
      "\n",
      "Epoch 479/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 35us/step - loss: 1.3909 - acc: 0.4861 - val_loss: 1.5712 - val_acc: 0.5208\n",
      "\n",
      "Epoch 480/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 32us/step - loss: 1.4617 - acc: 0.4306 - val_loss: 1.5797 - val_acc: 0.4792\n",
      "\n",
      "Epoch 481/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 36us/step - loss: 1.4699 - acc: 0.4352 - val_loss: 1.5826 - val_acc: 0.5417\n",
      "\n",
      "Epoch 482/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 34us/step - loss: 1.4066 - acc: 0.4954 - val_loss: 1.5779 - val_acc: 0.5208\n",
      "\n",
      "Epoch 483/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 33us/step - loss: 1.4546 - acc: 0.4954 - val_loss: 1.5784 - val_acc: 0.5208\n",
      "\n",
      "Epoch 484/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 34us/step - loss: 1.4306 - acc: 0.4583 - val_loss: 1.5737 - val_acc: 0.5000\n",
      "\n",
      "Epoch 485/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 35us/step - loss: 1.4960 - acc: 0.4213 - val_loss: 1.5688 - val_acc: 0.5000\n",
      "\n",
      "Epoch 486/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 39us/step - loss: 1.5315 - acc: 0.3750 - val_loss: 1.5674 - val_acc: 0.5417\n",
      "\n",
      "Epoch 487/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 32us/step - loss: 1.4553 - acc: 0.4444 - val_loss: 1.5743 - val_acc: 0.5208\n",
      "\n",
      "Epoch 488/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 31us/step - loss: 1.4514 - acc: 0.4491 - val_loss: 1.5697 - val_acc: 0.5208\n",
      "\n",
      "Epoch 489/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 39us/step - loss: 1.3696 - acc: 0.4954 - val_loss: 1.5692 - val_acc: 0.5000\n",
      "\n",
      "Epoch 490/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 72us/step - loss: 1.4360 - acc: 0.4259 - val_loss: 1.5715 - val_acc: 0.5000\n",
      "\n",
      "Epoch 491/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 42us/step - loss: 1.4266 - acc: 0.4769 - val_loss: 1.5755 - val_acc: 0.4792\n",
      "\n",
      "Epoch 492/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 40us/step - loss: 1.3979 - acc: 0.5000 - val_loss: 1.5748 - val_acc: 0.4792\n",
      "\n",
      "Epoch 493/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 36us/step - loss: 1.3990 - acc: 0.5093 - val_loss: 1.5766 - val_acc: 0.5000\n",
      "\n",
      "Epoch 494/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 42us/step - loss: 1.4454 - acc: 0.4907 - val_loss: 1.5826 - val_acc: 0.5000\n",
      "\n",
      "Epoch 495/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 41us/step - loss: 1.4517 - acc: 0.4861 - val_loss: 1.5800 - val_acc: 0.5000\n",
      "\n",
      "Epoch 496/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 40us/step - loss: 1.4545 - acc: 0.4722 - val_loss: 1.5790 - val_acc: 0.4792\n",
      "\n",
      "Epoch 497/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 35us/step - loss: 1.4528 - acc: 0.4583 - val_loss: 1.5741 - val_acc: 0.4792\n",
      "\n",
      "Epoch 498/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 30us/step - loss: 1.4280 - acc: 0.4398 - val_loss: 1.5812 - val_acc: 0.4792\n",
      "\n",
      "Epoch 499/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 32us/step - loss: 1.3697 - acc: 0.4861 - val_loss: 1.5770 - val_acc: 0.5000\n",
      "\n",
      "Epoch 500/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 42us/step - loss: 1.3291 - acc: 0.4769 - val_loss: 1.5828 - val_acc: 0.5208\n",
      "\n",
      "Epoch 501/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 42us/step - loss: 1.4210 - acc: 0.4352 - val_loss: 1.5825 - val_acc: 0.5208\n",
      "\n",
      "Epoch 502/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 52us/step - loss: 1.4963 - acc: 0.4769 - val_loss: 1.5824 - val_acc: 0.5000\n",
      "\n",
      "Epoch 503/1200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "216/216 [==============================]216/216 [==============================] - 0s 76us/step - loss: 1.4493 - acc: 0.4769 - val_loss: 1.5838 - val_acc: 0.5000\n",
      "\n",
      "Epoch 504/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 166us/step - loss: 1.3921 - acc: 0.4954 - val_loss: 1.5863 - val_acc: 0.5000\n",
      "\n",
      "Epoch 505/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 100us/step - loss: 1.4925 - acc: 0.4259 - val_loss: 1.5785 - val_acc: 0.5208\n",
      "\n",
      "Epoch 506/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 100us/step - loss: 1.4373 - acc: 0.4583 - val_loss: 1.5831 - val_acc: 0.5208\n",
      "\n",
      "Epoch 507/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 105us/step - loss: 1.4207 - acc: 0.4630 - val_loss: 1.5853 - val_acc: 0.5208\n",
      "\n",
      "Epoch 508/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 100us/step - loss: 1.4350 - acc: 0.4352 - val_loss: 1.5901 - val_acc: 0.5208\n",
      "\n",
      "Epoch 509/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 105us/step - loss: 1.4143 - acc: 0.4861 - val_loss: 1.5925 - val_acc: 0.5208\n",
      "\n",
      "Epoch 510/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 106us/step - loss: 1.4437 - acc: 0.4491 - val_loss: 1.5869 - val_acc: 0.5208\n",
      "\n",
      "Epoch 511/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 171us/step - loss: 1.5190 - acc: 0.4259 - val_loss: 1.5823 - val_acc: 0.4792\n",
      "\n",
      "Epoch 512/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 110us/step - loss: 1.4247 - acc: 0.4444 - val_loss: 1.5732 - val_acc: 0.5208\n",
      "\n",
      "Epoch 513/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 122us/step - loss: 1.4536 - acc: 0.5046 - val_loss: 1.5740 - val_acc: 0.5208\n",
      "\n",
      "Epoch 514/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 109us/step - loss: 1.4382 - acc: 0.4630 - val_loss: 1.5767 - val_acc: 0.5208\n",
      "\n",
      "Epoch 515/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 96us/step - loss: 1.4341 - acc: 0.5000 - val_loss: 1.5718 - val_acc: 0.5208\n",
      "\n",
      "Epoch 516/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 122us/step - loss: 1.4421 - acc: 0.4722 - val_loss: 1.5780 - val_acc: 0.5208\n",
      "\n",
      "Epoch 517/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 86us/step - loss: 1.5010 - acc: 0.4398 - val_loss: 1.5772 - val_acc: 0.5000\n",
      "\n",
      "Epoch 518/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 106us/step - loss: 1.4615 - acc: 0.4630 - val_loss: 1.5694 - val_acc: 0.5208\n",
      "\n",
      "Epoch 519/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 102us/step - loss: 1.4009 - acc: 0.4398 - val_loss: 1.5744 - val_acc: 0.4792\n",
      "\n",
      "Epoch 520/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 170us/step - loss: 1.4339 - acc: 0.4722 - val_loss: 1.5759 - val_acc: 0.4792\n",
      "\n",
      "Epoch 521/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 84us/step - loss: 1.4223 - acc: 0.4769 - val_loss: 1.5735 - val_acc: 0.5000\n",
      "\n",
      "Epoch 522/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 102us/step - loss: 1.4233 - acc: 0.4583 - val_loss: 1.5866 - val_acc: 0.4792\n",
      "\n",
      "Epoch 523/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 116us/step - loss: 1.4811 - acc: 0.4907 - val_loss: 1.5872 - val_acc: 0.4792\n",
      "\n",
      "Epoch 524/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 114us/step - loss: 1.3976 - acc: 0.4861 - val_loss: 1.5775 - val_acc: 0.5000\n",
      "\n",
      "Epoch 525/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 105us/step - loss: 1.4392 - acc: 0.4583 - val_loss: 1.5722 - val_acc: 0.5208\n",
      "\n",
      "Epoch 526/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 115us/step - loss: 1.4793 - acc: 0.4491 - val_loss: 1.5809 - val_acc: 0.5208\n",
      "\n",
      "Epoch 527/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 111us/step - loss: 1.3906 - acc: 0.4769 - val_loss: 1.5848 - val_acc: 0.5000\n",
      "\n",
      "Epoch 528/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 161us/step - loss: 1.4904 - acc: 0.4583 - val_loss: 1.5807 - val_acc: 0.5208\n",
      "\n",
      "Epoch 529/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 102us/step - loss: 1.4284 - acc: 0.5093 - val_loss: 1.5812 - val_acc: 0.5208\n",
      "\n",
      "Epoch 530/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 94us/step - loss: 1.4663 - acc: 0.4630 - val_loss: 1.5782 - val_acc: 0.5000\n",
      "\n",
      "Epoch 531/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 97us/step - loss: 1.4883 - acc: 0.4306 - val_loss: 1.5737 - val_acc: 0.5208\n",
      "\n",
      "Epoch 532/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 156us/step - loss: 1.4523 - acc: 0.4537 - val_loss: 1.5848 - val_acc: 0.5000\n",
      "\n",
      "Epoch 533/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 100us/step - loss: 1.3950 - acc: 0.4722 - val_loss: 1.5847 - val_acc: 0.5000\n",
      "\n",
      "Epoch 534/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 101us/step - loss: 1.4741 - acc: 0.4769 - val_loss: 1.5827 - val_acc: 0.5000\n",
      "\n",
      "Epoch 535/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 112us/step - loss: 1.4391 - acc: 0.4954 - val_loss: 1.5841 - val_acc: 0.5208\n",
      "\n",
      "Epoch 536/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 133us/step - loss: 1.3766 - acc: 0.5278 - val_loss: 1.5823 - val_acc: 0.5000\n",
      "\n",
      "Epoch 537/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 90us/step - loss: 1.4300 - acc: 0.4861 - val_loss: 1.5903 - val_acc: 0.5208\n",
      "\n",
      "Epoch 538/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 106us/step - loss: 1.3746 - acc: 0.4676 - val_loss: 1.6005 - val_acc: 0.5000\n",
      "\n",
      "Epoch 539/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 96us/step - loss: 1.4332 - acc: 0.4861 - val_loss: 1.5993 - val_acc: 0.5000\n",
      "\n",
      "Epoch 540/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 84us/step - loss: 1.4609 - acc: 0.4630 - val_loss: 1.5994 - val_acc: 0.5000\n",
      "\n",
      "Epoch 541/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 76us/step - loss: 1.3867 - acc: 0.5139 - val_loss: 1.6037 - val_acc: 0.5000\n",
      "\n",
      "Epoch 542/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 108us/step - loss: 1.3520 - acc: 0.4861 - val_loss: 1.5918 - val_acc: 0.5000\n",
      "\n",
      "Epoch 543/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 96us/step - loss: 1.4326 - acc: 0.4537 - val_loss: 1.5940 - val_acc: 0.5000\n",
      "\n",
      "Epoch 544/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 90us/step - loss: 1.4014 - acc: 0.4630 - val_loss: 1.5916 - val_acc: 0.5000\n",
      "\n",
      "Epoch 545/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 98us/step - loss: 1.4556 - acc: 0.4167 - val_loss: 1.5976 - val_acc: 0.5000\n",
      "\n",
      "Epoch 546/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 103us/step - loss: 1.4308 - acc: 0.4722 - val_loss: 1.5968 - val_acc: 0.4792\n",
      "\n",
      "Epoch 547/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 97us/step - loss: 1.4205 - acc: 0.4722 - val_loss: 1.5965 - val_acc: 0.5000\n",
      "\n",
      "Epoch 548/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 93us/step - loss: 1.3473 - acc: 0.5093 - val_loss: 1.5986 - val_acc: 0.5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 549/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 79us/step - loss: 1.3847 - acc: 0.4907 - val_loss: 1.5968 - val_acc: 0.5000\n",
      "\n",
      "Epoch 550/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 94us/step - loss: 1.4506 - acc: 0.4491 - val_loss: 1.5939 - val_acc: 0.5000\n",
      "\n",
      "Epoch 551/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 84us/step - loss: 1.4597 - acc: 0.4630 - val_loss: 1.6048 - val_acc: 0.5000\n",
      "\n",
      "Epoch 552/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 99us/step - loss: 1.4494 - acc: 0.4676 - val_loss: 1.6021 - val_acc: 0.5000\n",
      "\n",
      "Epoch 553/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 100us/step - loss: 1.4062 - acc: 0.5093 - val_loss: 1.6114 - val_acc: 0.5208\n",
      "\n",
      "Epoch 554/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 101us/step - loss: 1.4240 - acc: 0.4259 - val_loss: 1.6249 - val_acc: 0.5000\n",
      "\n",
      "Epoch 555/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 81us/step - loss: 1.3842 - acc: 0.4491 - val_loss: 1.6079 - val_acc: 0.5000\n",
      "\n",
      "Epoch 556/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 34us/step - loss: 1.4285 - acc: 0.4769 - val_loss: 1.6003 - val_acc: 0.5208\n",
      "\n",
      "Epoch 557/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 34us/step - loss: 1.4553 - acc: 0.4352 - val_loss: 1.6064 - val_acc: 0.5000\n",
      "\n",
      "Epoch 558/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 38us/step - loss: 1.3594 - acc: 0.5556 - val_loss: 1.6008 - val_acc: 0.5000\n",
      "\n",
      "Epoch 559/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 34us/step - loss: 1.4326 - acc: 0.4537 - val_loss: 1.6026 - val_acc: 0.5000\n",
      "\n",
      "Epoch 560/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 35us/step - loss: 1.4664 - acc: 0.4722 - val_loss: 1.5957 - val_acc: 0.5208\n",
      "\n",
      "Epoch 561/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 33us/step - loss: 1.3276 - acc: 0.5231 - val_loss: 1.6014 - val_acc: 0.5208\n",
      "\n",
      "Epoch 562/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 34us/step - loss: 1.4090 - acc: 0.4815 - val_loss: 1.6046 - val_acc: 0.5208\n",
      "\n",
      "Epoch 563/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 34us/step - loss: 1.4368 - acc: 0.4583 - val_loss: 1.6019 - val_acc: 0.5417\n",
      "\n",
      "Epoch 564/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 83us/step - loss: 1.4165 - acc: 0.4815 - val_loss: 1.6060 - val_acc: 0.5208\n",
      "\n",
      "Epoch 565/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 40us/step - loss: 1.3502 - acc: 0.5093 - val_loss: 1.6093 - val_acc: 0.4792\n",
      "\n",
      "Epoch 566/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 32us/step - loss: 1.3372 - acc: 0.5509 - val_loss: 1.6040 - val_acc: 0.5000\n",
      "\n",
      "Epoch 567/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 31us/step - loss: 1.4243 - acc: 0.4861 - val_loss: 1.6050 - val_acc: 0.5000\n",
      "\n",
      "Epoch 568/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 32us/step - loss: 1.4848 - acc: 0.4861 - val_loss: 1.6086 - val_acc: 0.5000\n",
      "\n",
      "Epoch 569/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 30us/step - loss: 1.3845 - acc: 0.5139 - val_loss: 1.6095 - val_acc: 0.5208\n",
      "\n",
      "Epoch 570/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 36us/step - loss: 1.4388 - acc: 0.5093 - val_loss: 1.6021 - val_acc: 0.5417\n",
      "\n",
      "Epoch 571/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 32us/step - loss: 1.4307 - acc: 0.4722 - val_loss: 1.6046 - val_acc: 0.5208\n",
      "\n",
      "Epoch 572/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 33us/step - loss: 1.3997 - acc: 0.5046 - val_loss: 1.6078 - val_acc: 0.5000\n",
      "\n",
      "Epoch 573/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 30us/step - loss: 1.3857 - acc: 0.5046 - val_loss: 1.6052 - val_acc: 0.4583\n",
      "\n",
      "Epoch 574/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 38us/step - loss: 1.4169 - acc: 0.4722 - val_loss: 1.6115 - val_acc: 0.5000\n",
      "\n",
      "Epoch 575/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 32us/step - loss: 1.3539 - acc: 0.4861 - val_loss: 1.6055 - val_acc: 0.4792\n",
      "\n",
      "Epoch 576/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 40us/step - loss: 1.3911 - acc: 0.5278 - val_loss: 1.6125 - val_acc: 0.5000\n",
      "\n",
      "Epoch 577/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 33us/step - loss: 1.4646 - acc: 0.4630 - val_loss: 1.6108 - val_acc: 0.4792\n",
      "\n",
      "Epoch 578/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 34us/step - loss: 1.4414 - acc: 0.4769 - val_loss: 1.6068 - val_acc: 0.5000\n",
      "\n",
      "Epoch 579/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 37us/step - loss: 1.4807 - acc: 0.4259 - val_loss: 1.6006 - val_acc: 0.4792\n",
      "\n",
      "Epoch 580/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 31us/step - loss: 1.3962 - acc: 0.4306 - val_loss: 1.5964 - val_acc: 0.4792\n",
      "\n",
      "Epoch 581/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 33us/step - loss: 1.3813 - acc: 0.4583 - val_loss: 1.6000 - val_acc: 0.5000\n",
      "\n",
      "Epoch 582/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 33us/step - loss: 1.4116 - acc: 0.4306 - val_loss: 1.6099 - val_acc: 0.4792\n",
      "\n",
      "Epoch 583/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 33us/step - loss: 1.4268 - acc: 0.4491 - val_loss: 1.6088 - val_acc: 0.5000\n",
      "\n",
      "Epoch 584/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 46us/step - loss: 1.3909 - acc: 0.5093 - val_loss: 1.6061 - val_acc: 0.4792\n",
      "\n",
      "Epoch 585/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 32us/step - loss: 1.3801 - acc: 0.5046 - val_loss: 1.6094 - val_acc: 0.5000\n",
      "\n",
      "Epoch 586/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 31us/step - loss: 1.4278 - acc: 0.4444 - val_loss: 1.6036 - val_acc: 0.4792\n",
      "\n",
      "Epoch 587/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 35us/step - loss: 1.4507 - acc: 0.4213 - val_loss: 1.6070 - val_acc: 0.4792\n",
      "\n",
      "Epoch 588/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 32us/step - loss: 1.4066 - acc: 0.4722 - val_loss: 1.6164 - val_acc: 0.5000\n",
      "\n",
      "Epoch 589/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 37us/step - loss: 1.4149 - acc: 0.4630 - val_loss: 1.6073 - val_acc: 0.5208\n",
      "\n",
      "Epoch 590/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 41us/step - loss: 1.4134 - acc: 0.4676 - val_loss: 1.6011 - val_acc: 0.5000\n",
      "\n",
      "Epoch 591/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 37us/step - loss: 1.3602 - acc: 0.5000 - val_loss: 1.6052 - val_acc: 0.5208\n",
      "\n",
      "Epoch 592/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 35us/step - loss: 1.4188 - acc: 0.4815 - val_loss: 1.6158 - val_acc: 0.5000\n",
      "\n",
      "Epoch 593/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 50us/step - loss: 1.3528 - acc: 0.4815 - val_loss: 1.6198 - val_acc: 0.5208\n",
      "\n",
      "Epoch 594/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 32us/step - loss: 1.3658 - acc: 0.4954 - val_loss: 1.6047 - val_acc: 0.5208\n",
      "\n",
      "Epoch 595/1200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "216/216 [==============================]216/216 [==============================] - 0s 32us/step - loss: 1.3861 - acc: 0.4815 - val_loss: 1.6101 - val_acc: 0.4792\n",
      "\n",
      "Epoch 596/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 31us/step - loss: 1.3658 - acc: 0.4537 - val_loss: 1.6047 - val_acc: 0.5000\n",
      "\n",
      "Epoch 597/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 34us/step - loss: 1.4138 - acc: 0.5046 - val_loss: 1.6123 - val_acc: 0.4792\n",
      "\n",
      "Epoch 598/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 33us/step - loss: 1.3706 - acc: 0.4907 - val_loss: 1.6165 - val_acc: 0.4792\n",
      "\n",
      "Epoch 599/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 40us/step - loss: 1.3706 - acc: 0.5231 - val_loss: 1.6133 - val_acc: 0.5208\n",
      "\n",
      "Epoch 600/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 33us/step - loss: 1.3775 - acc: 0.4630 - val_loss: 1.6098 - val_acc: 0.5208\n",
      "\n",
      "Epoch 601/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 35us/step - loss: 1.3948 - acc: 0.4074 - val_loss: 1.6051 - val_acc: 0.5000\n",
      "\n",
      "Epoch 602/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 32us/step - loss: 1.3480 - acc: 0.5000 - val_loss: 1.6062 - val_acc: 0.4792\n",
      "\n",
      "Epoch 603/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 34us/step - loss: 1.4143 - acc: 0.4954 - val_loss: 1.6173 - val_acc: 0.5000\n",
      "\n",
      "Epoch 604/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 33us/step - loss: 1.3424 - acc: 0.4769 - val_loss: 1.6202 - val_acc: 0.4792\n",
      "\n",
      "Epoch 605/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 36us/step - loss: 1.4077 - acc: 0.4861 - val_loss: 1.6233 - val_acc: 0.5000\n",
      "\n",
      "Epoch 606/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 39us/step - loss: 1.3915 - acc: 0.4769 - val_loss: 1.6215 - val_acc: 0.5208\n",
      "\n",
      "Epoch 607/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 33us/step - loss: 1.3399 - acc: 0.4722 - val_loss: 1.6121 - val_acc: 0.5208\n",
      "\n",
      "Epoch 608/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 33us/step - loss: 1.3323 - acc: 0.5000 - val_loss: 1.6074 - val_acc: 0.5000\n",
      "\n",
      "Epoch 609/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 31us/step - loss: 1.2678 - acc: 0.5417 - val_loss: 1.6217 - val_acc: 0.5000\n",
      "\n",
      "Epoch 610/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 34us/step - loss: 1.4583 - acc: 0.4259 - val_loss: 1.6208 - val_acc: 0.5000\n",
      "\n",
      "Epoch 611/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 42us/step - loss: 1.3560 - acc: 0.4583 - val_loss: 1.6226 - val_acc: 0.4792\n",
      "\n",
      "Epoch 612/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 38us/step - loss: 1.3346 - acc: 0.5324 - val_loss: 1.6282 - val_acc: 0.4792\n",
      "\n",
      "Epoch 613/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 30us/step - loss: 1.3394 - acc: 0.5417 - val_loss: 1.6242 - val_acc: 0.4792\n",
      "\n",
      "Epoch 614/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 34us/step - loss: 1.4170 - acc: 0.4769 - val_loss: 1.6260 - val_acc: 0.5208\n",
      "\n",
      "Epoch 615/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 34us/step - loss: 1.4256 - acc: 0.5000 - val_loss: 1.6239 - val_acc: 0.4583\n",
      "\n",
      "Epoch 616/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 51us/step - loss: 1.3852 - acc: 0.4722 - val_loss: 1.6151 - val_acc: 0.5000\n",
      "\n",
      "Epoch 617/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 58us/step - loss: 1.4107 - acc: 0.4630 - val_loss: 1.6089 - val_acc: 0.4792\n",
      "\n",
      "Epoch 618/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 50us/step - loss: 1.3489 - acc: 0.4907 - val_loss: 1.6133 - val_acc: 0.4792\n",
      "\n",
      "Epoch 619/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 43us/step - loss: 1.4474 - acc: 0.4398 - val_loss: 1.6237 - val_acc: 0.5000\n",
      "\n",
      "Epoch 620/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 101us/step - loss: 1.4205 - acc: 0.4444 - val_loss: 1.6119 - val_acc: 0.4792\n",
      "\n",
      "Epoch 621/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 95us/step - loss: 1.2986 - acc: 0.5000 - val_loss: 1.6086 - val_acc: 0.5417\n",
      "\n",
      "Epoch 622/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 224us/step - loss: 1.2795 - acc: 0.5231 - val_loss: 1.6143 - val_acc: 0.4375\n",
      "\n",
      "Epoch 623/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 103us/step - loss: 1.3858 - acc: 0.4861 - val_loss: 1.6187 - val_acc: 0.4792\n",
      "\n",
      "Epoch 624/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 112us/step - loss: 1.3294 - acc: 0.4907 - val_loss: 1.6194 - val_acc: 0.4583\n",
      "\n",
      "Epoch 625/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 108us/step - loss: 1.4113 - acc: 0.4676 - val_loss: 1.6206 - val_acc: 0.5000\n",
      "\n",
      "Epoch 626/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 104us/step - loss: 1.3882 - acc: 0.4722 - val_loss: 1.6202 - val_acc: 0.4792\n",
      "\n",
      "Epoch 627/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 101us/step - loss: 1.3301 - acc: 0.4954 - val_loss: 1.6205 - val_acc: 0.4583\n",
      "\n",
      "Epoch 628/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 97us/step - loss: 1.3590 - acc: 0.5093 - val_loss: 1.6301 - val_acc: 0.5000\n",
      "\n",
      "Epoch 629/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 106us/step - loss: 1.3325 - acc: 0.5278 - val_loss: 1.6260 - val_acc: 0.5208\n",
      "\n",
      "Epoch 630/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 106us/step - loss: 1.4842 - acc: 0.4444 - val_loss: 1.6314 - val_acc: 0.4792\n",
      "\n",
      "Epoch 631/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 106us/step - loss: 1.3882 - acc: 0.4861 - val_loss: 1.6230 - val_acc: 0.4792\n",
      "\n",
      "Epoch 632/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 116us/step - loss: 1.4225 - acc: 0.4907 - val_loss: 1.6238 - val_acc: 0.4792\n",
      "\n",
      "Epoch 633/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 105us/step - loss: 1.3385 - acc: 0.5046 - val_loss: 1.6371 - val_acc: 0.4792\n",
      "\n",
      "Epoch 634/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 105us/step - loss: 1.4054 - acc: 0.4630 - val_loss: 1.6282 - val_acc: 0.4792\n",
      "\n",
      "Epoch 635/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 226us/step - loss: 1.3576 - acc: 0.4769 - val_loss: 1.6230 - val_acc: 0.5000\n",
      "\n",
      "Epoch 636/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 102us/step - loss: 1.3780 - acc: 0.5139 - val_loss: 1.6216 - val_acc: 0.4792\n",
      "\n",
      "Epoch 637/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 105us/step - loss: 1.3850 - acc: 0.4954 - val_loss: 1.6131 - val_acc: 0.5000\n",
      "\n",
      "Epoch 638/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 105us/step - loss: 1.3552 - acc: 0.5278 - val_loss: 1.6196 - val_acc: 0.4792\n",
      "\n",
      "Epoch 639/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 138us/step - loss: 1.3588 - acc: 0.5093 - val_loss: 1.6185 - val_acc: 0.4792\n",
      "\n",
      "Epoch 640/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 122us/step - loss: 1.3337 - acc: 0.5231 - val_loss: 1.6197 - val_acc: 0.4792\n",
      "\n",
      "Epoch 641/1200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "216/216 [==============================]216/216 [==============================] - 0s 107us/step - loss: 1.4227 - acc: 0.4769 - val_loss: 1.6155 - val_acc: 0.5000\n",
      "\n",
      "Epoch 642/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 107us/step - loss: 1.3956 - acc: 0.4815 - val_loss: 1.6218 - val_acc: 0.4792\n",
      "\n",
      "Epoch 643/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 112us/step - loss: 1.3673 - acc: 0.4907 - val_loss: 1.6119 - val_acc: 0.4792\n",
      "\n",
      "Epoch 644/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 103us/step - loss: 1.3652 - acc: 0.5093 - val_loss: 1.6248 - val_acc: 0.5000\n",
      "\n",
      "Epoch 645/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 142us/step - loss: 1.3726 - acc: 0.4907 - val_loss: 1.6313 - val_acc: 0.4792\n",
      "\n",
      "Epoch 646/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 81us/step - loss: 1.3713 - acc: 0.4722 - val_loss: 1.6285 - val_acc: 0.4792\n",
      "\n",
      "Epoch 647/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 89us/step - loss: 1.2904 - acc: 0.4907 - val_loss: 1.6313 - val_acc: 0.4792\n",
      "\n",
      "Epoch 648/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 86us/step - loss: 1.3544 - acc: 0.4722 - val_loss: 1.6227 - val_acc: 0.4792\n",
      "\n",
      "Epoch 649/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 101us/step - loss: 1.2926 - acc: 0.5139 - val_loss: 1.6309 - val_acc: 0.4792\n",
      "\n",
      "Epoch 650/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 93us/step - loss: 1.3095 - acc: 0.5185 - val_loss: 1.6272 - val_acc: 0.4792\n",
      "\n",
      "Epoch 651/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 85us/step - loss: 1.3917 - acc: 0.4907 - val_loss: 1.6152 - val_acc: 0.4583\n",
      "\n",
      "Epoch 652/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 93us/step - loss: 1.4181 - acc: 0.4676 - val_loss: 1.6305 - val_acc: 0.4792\n",
      "\n",
      "Epoch 653/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 83us/step - loss: 1.2885 - acc: 0.5093 - val_loss: 1.6300 - val_acc: 0.4792\n",
      "\n",
      "Epoch 654/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 100us/step - loss: 1.4042 - acc: 0.4676 - val_loss: 1.6381 - val_acc: 0.4792\n",
      "\n",
      "Epoch 655/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 98us/step - loss: 1.3277 - acc: 0.4722 - val_loss: 1.6364 - val_acc: 0.4583\n",
      "\n",
      "Epoch 656/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 89us/step - loss: 1.3701 - acc: 0.5046 - val_loss: 1.6314 - val_acc: 0.4792\n",
      "\n",
      "Epoch 657/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 93us/step - loss: 1.3171 - acc: 0.5185 - val_loss: 1.6316 - val_acc: 0.5000\n",
      "\n",
      "Epoch 658/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 91us/step - loss: 1.3143 - acc: 0.5093 - val_loss: 1.6251 - val_acc: 0.5000\n",
      "\n",
      "Epoch 659/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 104us/step - loss: 1.3877 - acc: 0.4630 - val_loss: 1.6353 - val_acc: 0.4583\n",
      "\n",
      "Epoch 660/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 86us/step - loss: 1.3510 - acc: 0.5231 - val_loss: 1.6364 - val_acc: 0.4583\n",
      "\n",
      "Epoch 661/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 79us/step - loss: 1.3698 - acc: 0.5139 - val_loss: 1.6356 - val_acc: 0.4583\n",
      "\n",
      "Epoch 662/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 91us/step - loss: 1.3534 - acc: 0.5463 - val_loss: 1.6294 - val_acc: 0.4792\n",
      "\n",
      "Epoch 663/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 87us/step - loss: 1.3398 - acc: 0.5046 - val_loss: 1.6298 - val_acc: 0.4792\n",
      "\n",
      "Epoch 664/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 98us/step - loss: 1.2538 - acc: 0.5694 - val_loss: 1.6292 - val_acc: 0.5000\n",
      "\n",
      "Epoch 665/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 88us/step - loss: 1.3934 - acc: 0.4861 - val_loss: 1.6307 - val_acc: 0.4792\n",
      "\n",
      "Epoch 666/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 88us/step - loss: 1.3503 - acc: 0.5139 - val_loss: 1.6320 - val_acc: 0.4792\n",
      "\n",
      "Epoch 667/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 100us/step - loss: 1.2989 - acc: 0.5463 - val_loss: 1.6280 - val_acc: 0.5000\n",
      "\n",
      "Epoch 668/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 101us/step - loss: 1.3718 - acc: 0.5463 - val_loss: 1.6326 - val_acc: 0.4792\n",
      "\n",
      "Epoch 669/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 89us/step - loss: 1.3091 - acc: 0.5046 - val_loss: 1.6220 - val_acc: 0.4792\n",
      "\n",
      "Epoch 670/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 99us/step - loss: 1.2961 - acc: 0.5417 - val_loss: 1.6271 - val_acc: 0.4792\n",
      "\n",
      "Epoch 671/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 91us/step - loss: 1.2983 - acc: 0.5231 - val_loss: 1.6234 - val_acc: 0.4792\n",
      "\n",
      "Epoch 672/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 81us/step - loss: 1.3724 - acc: 0.5000 - val_loss: 1.6190 - val_acc: 0.4792\n",
      "\n",
      "Epoch 673/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 81us/step - loss: 1.2718 - acc: 0.5463 - val_loss: 1.6257 - val_acc: 0.4792\n",
      "\n",
      "Epoch 674/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 38us/step - loss: 1.3357 - acc: 0.5000 - val_loss: 1.6256 - val_acc: 0.4792\n",
      "\n",
      "Epoch 675/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 42us/step - loss: 1.3714 - acc: 0.5463 - val_loss: 1.6209 - val_acc: 0.4583\n",
      "\n",
      "Epoch 676/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 32us/step - loss: 1.3867 - acc: 0.4537 - val_loss: 1.6169 - val_acc: 0.4792\n",
      "\n",
      "Epoch 677/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 35us/step - loss: 1.2994 - acc: 0.5278 - val_loss: 1.6226 - val_acc: 0.4792\n",
      "\n",
      "Epoch 678/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 36us/step - loss: 1.4007 - acc: 0.4444 - val_loss: 1.6235 - val_acc: 0.5000\n",
      "\n",
      "Epoch 679/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 35us/step - loss: 1.4070 - acc: 0.4630 - val_loss: 1.6286 - val_acc: 0.4792\n",
      "\n",
      "Epoch 680/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 43us/step - loss: 1.3113 - acc: 0.5046 - val_loss: 1.6245 - val_acc: 0.5000\n",
      "\n",
      "Epoch 681/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 33us/step - loss: 1.3518 - acc: 0.5046 - val_loss: 1.6260 - val_acc: 0.5000\n",
      "\n",
      "Epoch 682/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 36us/step - loss: 1.4867 - acc: 0.4398 - val_loss: 1.6242 - val_acc: 0.5000\n",
      "\n",
      "Epoch 683/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 38us/step - loss: 1.3334 - acc: 0.5185 - val_loss: 1.6223 - val_acc: 0.5000\n",
      "\n",
      "Epoch 684/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 32us/step - loss: 1.3679 - acc: 0.5139 - val_loss: 1.6334 - val_acc: 0.5208\n",
      "\n",
      "Epoch 685/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 37us/step - loss: 1.3596 - acc: 0.5278 - val_loss: 1.6320 - val_acc: 0.4792\n",
      "\n",
      "Epoch 686/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 32us/step - loss: 1.3451 - acc: 0.5000 - val_loss: 1.6368 - val_acc: 0.5000\n",
      "\n",
      "Epoch 687/1200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "216/216 [==============================]216/216 [==============================] - 0s 34us/step - loss: 1.2979 - acc: 0.5185 - val_loss: 1.6387 - val_acc: 0.5208\n",
      "\n",
      "Epoch 688/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 32us/step - loss: 1.3677 - acc: 0.4676 - val_loss: 1.6426 - val_acc: 0.4792\n",
      "\n",
      "Epoch 689/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 32us/step - loss: 1.2973 - acc: 0.5093 - val_loss: 1.6514 - val_acc: 0.4583\n",
      "\n",
      "Epoch 690/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 33us/step - loss: 1.3037 - acc: 0.5046 - val_loss: 1.6456 - val_acc: 0.4583\n",
      "\n",
      "Epoch 691/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 36us/step - loss: 1.2929 - acc: 0.5093 - val_loss: 1.6358 - val_acc: 0.4583\n",
      "\n",
      "Epoch 692/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 32us/step - loss: 1.3227 - acc: 0.4722 - val_loss: 1.6367 - val_acc: 0.4375\n",
      "\n",
      "Epoch 693/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 44us/step - loss: 1.3441 - acc: 0.5000 - val_loss: 1.6376 - val_acc: 0.4792\n",
      "\n",
      "Epoch 694/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 69us/step - loss: 1.3419 - acc: 0.5231 - val_loss: 1.6398 - val_acc: 0.4583\n",
      "\n",
      "Epoch 695/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 32us/step - loss: 1.3381 - acc: 0.4861 - val_loss: 1.6364 - val_acc: 0.4792\n",
      "\n",
      "Epoch 696/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 33us/step - loss: 1.3079 - acc: 0.5185 - val_loss: 1.6358 - val_acc: 0.5000\n",
      "\n",
      "Epoch 697/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 31us/step - loss: 1.3705 - acc: 0.5231 - val_loss: 1.6379 - val_acc: 0.5000\n",
      "\n",
      "Epoch 698/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 34us/step - loss: 1.3761 - acc: 0.4907 - val_loss: 1.6423 - val_acc: 0.5000\n",
      "\n",
      "Epoch 699/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 35us/step - loss: 1.3916 - acc: 0.4676 - val_loss: 1.6326 - val_acc: 0.4792\n",
      "\n",
      "Epoch 700/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 35us/step - loss: 1.4036 - acc: 0.5093 - val_loss: 1.6389 - val_acc: 0.4792\n",
      "\n",
      "Epoch 701/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 35us/step - loss: 1.2873 - acc: 0.5093 - val_loss: 1.6351 - val_acc: 0.4792\n",
      "\n",
      "Epoch 702/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 39us/step - loss: 1.3438 - acc: 0.5417 - val_loss: 1.6416 - val_acc: 0.4792\n",
      "\n",
      "Epoch 703/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 37us/step - loss: 1.2934 - acc: 0.4861 - val_loss: 1.6391 - val_acc: 0.4792\n",
      "\n",
      "Epoch 704/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 34us/step - loss: 1.4448 - acc: 0.4352 - val_loss: 1.6420 - val_acc: 0.4792\n",
      "\n",
      "Epoch 705/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 32us/step - loss: 1.3070 - acc: 0.5046 - val_loss: 1.6430 - val_acc: 0.4792\n",
      "\n",
      "Epoch 706/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 38us/step - loss: 1.3615 - acc: 0.5139 - val_loss: 1.6373 - val_acc: 0.4792\n",
      "\n",
      "Epoch 707/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 33us/step - loss: 1.3494 - acc: 0.5093 - val_loss: 1.6361 - val_acc: 0.4792\n",
      "\n",
      "Epoch 708/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 35us/step - loss: 1.2745 - acc: 0.5093 - val_loss: 1.6535 - val_acc: 0.4792\n",
      "\n",
      "Epoch 709/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 32us/step - loss: 1.3332 - acc: 0.5185 - val_loss: 1.6478 - val_acc: 0.5000\n",
      "\n",
      "Epoch 710/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 34us/step - loss: 1.2417 - acc: 0.5278 - val_loss: 1.6396 - val_acc: 0.4792\n",
      "\n",
      "Epoch 711/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 33us/step - loss: 1.4239 - acc: 0.5093 - val_loss: 1.6331 - val_acc: 0.4792\n",
      "\n",
      "Epoch 712/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 31us/step - loss: 1.2938 - acc: 0.5463 - val_loss: 1.6459 - val_acc: 0.4792\n",
      "\n",
      "Epoch 713/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 37us/step - loss: 1.3076 - acc: 0.5185 - val_loss: 1.6365 - val_acc: 0.4792\n",
      "\n",
      "Epoch 714/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 32us/step - loss: 1.2430 - acc: 0.5046 - val_loss: 1.6496 - val_acc: 0.4792\n",
      "\n",
      "Epoch 715/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 32us/step - loss: 1.2756 - acc: 0.5509 - val_loss: 1.6523 - val_acc: 0.4583\n",
      "\n",
      "Epoch 716/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 32us/step - loss: 1.2642 - acc: 0.5278 - val_loss: 1.6523 - val_acc: 0.4792\n",
      "\n",
      "Epoch 717/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 34us/step - loss: 1.3647 - acc: 0.5046 - val_loss: 1.6451 - val_acc: 0.4792\n",
      "\n",
      "Epoch 718/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 33us/step - loss: 1.2855 - acc: 0.5000 - val_loss: 1.6548 - val_acc: 0.4792\n",
      "\n",
      "Epoch 719/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 36us/step - loss: 1.2874 - acc: 0.5231 - val_loss: 1.6580 - val_acc: 0.4792\n",
      "\n",
      "Epoch 720/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 42us/step - loss: 1.2848 - acc: 0.5463 - val_loss: 1.6541 - val_acc: 0.4792\n",
      "\n",
      "Epoch 721/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 45us/step - loss: 1.3710 - acc: 0.5046 - val_loss: 1.6539 - val_acc: 0.4792\n",
      "\n",
      "Epoch 722/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 35us/step - loss: 1.2947 - acc: 0.5278 - val_loss: 1.6426 - val_acc: 0.4792\n",
      "\n",
      "Epoch 723/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 42us/step - loss: 1.3050 - acc: 0.5093 - val_loss: 1.6503 - val_acc: 0.4792\n",
      "\n",
      "Epoch 724/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 31us/step - loss: 1.3462 - acc: 0.4907 - val_loss: 1.6392 - val_acc: 0.4792\n",
      "\n",
      "Epoch 725/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 30us/step - loss: 1.3384 - acc: 0.5093 - val_loss: 1.6446 - val_acc: 0.4583\n",
      "\n",
      "Epoch 726/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 31us/step - loss: 1.3055 - acc: 0.5185 - val_loss: 1.6486 - val_acc: 0.4792\n",
      "\n",
      "Epoch 727/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 39us/step - loss: 1.3155 - acc: 0.5185 - val_loss: 1.6392 - val_acc: 0.5000\n",
      "\n",
      "Epoch 728/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 52us/step - loss: 1.2699 - acc: 0.5046 - val_loss: 1.6487 - val_acc: 0.4583\n",
      "\n",
      "Epoch 729/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 37us/step - loss: 1.3164 - acc: 0.5000 - val_loss: 1.6387 - val_acc: 0.4792\n",
      "\n",
      "Epoch 730/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 44us/step - loss: 1.3079 - acc: 0.5046 - val_loss: 1.6446 - val_acc: 0.4583\n",
      "\n",
      "Epoch 731/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 52us/step - loss: 1.2477 - acc: 0.5509 - val_loss: 1.6389 - val_acc: 0.4792\n",
      "\n",
      "Epoch 732/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 214us/step - loss: 1.2962 - acc: 0.4954 - val_loss: 1.6438 - val_acc: 0.4792\n",
      "\n",
      "Epoch 733/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 109us/step - loss: 1.4114 - acc: 0.5046 - val_loss: 1.6392 - val_acc: 0.4792\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 734/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 108us/step - loss: 1.2371 - acc: 0.5139 - val_loss: 1.6421 - val_acc: 0.5000\n",
      "\n",
      "Epoch 735/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 124us/step - loss: 1.2779 - acc: 0.5139 - val_loss: 1.6487 - val_acc: 0.5000\n",
      "\n",
      "Epoch 736/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 110us/step - loss: 1.3586 - acc: 0.5278 - val_loss: 1.6403 - val_acc: 0.4792\n",
      "\n",
      "Epoch 737/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 107us/step - loss: 1.2954 - acc: 0.5000 - val_loss: 1.6538 - val_acc: 0.4792\n",
      "\n",
      "Epoch 738/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 172us/step - loss: 1.3333 - acc: 0.5185 - val_loss: 1.6533 - val_acc: 0.4792\n",
      "\n",
      "Epoch 739/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 84us/step - loss: 1.3548 - acc: 0.5093 - val_loss: 1.6502 - val_acc: 0.4792\n",
      "\n",
      "Epoch 740/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 84us/step - loss: 1.3617 - acc: 0.4954 - val_loss: 1.6456 - val_acc: 0.5000\n",
      "\n",
      "Epoch 741/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 127us/step - loss: 1.3682 - acc: 0.5046 - val_loss: 1.6551 - val_acc: 0.4792\n",
      "\n",
      "Epoch 742/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 108us/step - loss: 1.2745 - acc: 0.5370 - val_loss: 1.6664 - val_acc: 0.4792\n",
      "\n",
      "Epoch 743/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 161us/step - loss: 1.3613 - acc: 0.4398 - val_loss: 1.6508 - val_acc: 0.4792\n",
      "\n",
      "Epoch 744/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 131us/step - loss: 1.3571 - acc: 0.5046 - val_loss: 1.6549 - val_acc: 0.4792\n",
      "\n",
      "Epoch 745/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 91us/step - loss: 1.2635 - acc: 0.5417 - val_loss: 1.6412 - val_acc: 0.4792\n",
      "\n",
      "Epoch 746/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 92us/step - loss: 1.3065 - acc: 0.4861 - val_loss: 1.6513 - val_acc: 0.4792\n",
      "\n",
      "Epoch 747/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 92us/step - loss: 1.3448 - acc: 0.4954 - val_loss: 1.6545 - val_acc: 0.4583\n",
      "\n",
      "Epoch 748/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 99us/step - loss: 1.3486 - acc: 0.4722 - val_loss: 1.6553 - val_acc: 0.4583\n",
      "\n",
      "Epoch 749/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 112us/step - loss: 1.2902 - acc: 0.5370 - val_loss: 1.6535 - val_acc: 0.4792\n",
      "\n",
      "Epoch 750/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 86us/step - loss: 1.3588 - acc: 0.4676 - val_loss: 1.6590 - val_acc: 0.4792\n",
      "\n",
      "Epoch 751/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 94us/step - loss: 1.3365 - acc: 0.5000 - val_loss: 1.6529 - val_acc: 0.4792\n",
      "\n",
      "Epoch 752/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 84us/step - loss: 1.3446 - acc: 0.4954 - val_loss: 1.6506 - val_acc: 0.4792\n",
      "\n",
      "Epoch 753/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 99us/step - loss: 1.3094 - acc: 0.4954 - val_loss: 1.6600 - val_acc: 0.4792\n",
      "\n",
      "Epoch 754/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 91us/step - loss: 1.2976 - acc: 0.5694 - val_loss: 1.6617 - val_acc: 0.4583\n",
      "\n",
      "Epoch 755/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 108us/step - loss: 1.3403 - acc: 0.4769 - val_loss: 1.6676 - val_acc: 0.4583\n",
      "\n",
      "Epoch 756/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 91us/step - loss: 1.2706 - acc: 0.5556 - val_loss: 1.6621 - val_acc: 0.4792\n",
      "\n",
      "Epoch 757/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 101us/step - loss: 1.2397 - acc: 0.5556 - val_loss: 1.6773 - val_acc: 0.4792\n",
      "\n",
      "Epoch 758/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 95us/step - loss: 1.3481 - acc: 0.5093 - val_loss: 1.6605 - val_acc: 0.4583\n",
      "\n",
      "Epoch 759/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 106us/step - loss: 1.2751 - acc: 0.5417 - val_loss: 1.6597 - val_acc: 0.4792\n",
      "\n",
      "Epoch 760/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 100us/step - loss: 1.2181 - acc: 0.5509 - val_loss: 1.6575 - val_acc: 0.4792\n",
      "\n",
      "Epoch 761/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 100us/step - loss: 1.2389 - acc: 0.5417 - val_loss: 1.6603 - val_acc: 0.4792\n",
      "\n",
      "Epoch 762/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 106us/step - loss: 1.2907 - acc: 0.5278 - val_loss: 1.6615 - val_acc: 0.4792\n",
      "\n",
      "Epoch 763/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 111us/step - loss: 1.2639 - acc: 0.5324 - val_loss: 1.6524 - val_acc: 0.4792\n",
      "\n",
      "Epoch 764/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 105us/step - loss: 1.3206 - acc: 0.4861 - val_loss: 1.6647 - val_acc: 0.4583\n",
      "\n",
      "Epoch 765/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 172us/step - loss: 1.3484 - acc: 0.4630 - val_loss: 1.6499 - val_acc: 0.4583\n",
      "\n",
      "Epoch 766/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 101us/step - loss: 1.3323 - acc: 0.5185 - val_loss: 1.6567 - val_acc: 0.4583\n",
      "\n",
      "Epoch 767/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 116us/step - loss: 1.3165 - acc: 0.4769 - val_loss: 1.6459 - val_acc: 0.4583\n",
      "\n",
      "Epoch 768/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 95us/step - loss: 1.3928 - acc: 0.4676 - val_loss: 1.6659 - val_acc: 0.4583\n",
      "\n",
      "Epoch 769/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 96us/step - loss: 1.2654 - acc: 0.5278 - val_loss: 1.6660 - val_acc: 0.4583\n",
      "\n",
      "Epoch 770/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 134us/step - loss: 1.3874 - acc: 0.4676 - val_loss: 1.6694 - val_acc: 0.4792\n",
      "\n",
      "Epoch 771/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 80us/step - loss: 1.3218 - acc: 0.4815 - val_loss: 1.6648 - val_acc: 0.4792\n",
      "\n",
      "Epoch 772/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 100us/step - loss: 1.3417 - acc: 0.5093 - val_loss: 1.6719 - val_acc: 0.4583\n",
      "\n",
      "Epoch 773/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 94us/step - loss: 1.3010 - acc: 0.5370 - val_loss: 1.6561 - val_acc: 0.4583\n",
      "\n",
      "Epoch 774/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 106us/step - loss: 1.3162 - acc: 0.4722 - val_loss: 1.6610 - val_acc: 0.4792\n",
      "\n",
      "Epoch 775/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 109us/step - loss: 1.3010 - acc: 0.5509 - val_loss: 1.6516 - val_acc: 0.4792\n",
      "\n",
      "Epoch 776/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 99us/step - loss: 1.2642 - acc: 0.5509 - val_loss: 1.6596 - val_acc: 0.5000\n",
      "\n",
      "Epoch 777/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 93us/step - loss: 1.3139 - acc: 0.5463 - val_loss: 1.6533 - val_acc: 0.4792\n",
      "\n",
      "Epoch 778/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 98us/step - loss: 1.3320 - acc: 0.4815 - val_loss: 1.6512 - val_acc: 0.4792\n",
      "\n",
      "Epoch 779/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 89us/step - loss: 1.1938 - acc: 0.6019 - val_loss: 1.6666 - val_acc: 0.5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 780/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 135us/step - loss: 1.2359 - acc: 0.5463 - val_loss: 1.6674 - val_acc: 0.5000\n",
      "\n",
      "Epoch 781/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 88us/step - loss: 1.2868 - acc: 0.5139 - val_loss: 1.6687 - val_acc: 0.4792\n",
      "\n",
      "Epoch 782/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 96us/step - loss: 1.2886 - acc: 0.5000 - val_loss: 1.6618 - val_acc: 0.4583\n",
      "\n",
      "Epoch 783/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 65us/step - loss: 1.3096 - acc: 0.5046 - val_loss: 1.6611 - val_acc: 0.5000\n",
      "\n",
      "Epoch 784/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 33us/step - loss: 1.3055 - acc: 0.5370 - val_loss: 1.6596 - val_acc: 0.4792\n",
      "\n",
      "Epoch 785/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 39us/step - loss: 1.2417 - acc: 0.5463 - val_loss: 1.6528 - val_acc: 0.4792\n",
      "\n",
      "Epoch 786/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 38us/step - loss: 1.2469 - acc: 0.5324 - val_loss: 1.6602 - val_acc: 0.4792\n",
      "\n",
      "Epoch 787/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 35us/step - loss: 1.4149 - acc: 0.4676 - val_loss: 1.6524 - val_acc: 0.4792\n",
      "\n",
      "Epoch 788/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 36us/step - loss: 1.3453 - acc: 0.4676 - val_loss: 1.6585 - val_acc: 0.4792\n",
      "\n",
      "Epoch 789/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 32us/step - loss: 1.2744 - acc: 0.5324 - val_loss: 1.6479 - val_acc: 0.5000\n",
      "\n",
      "Epoch 790/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 35us/step - loss: 1.3198 - acc: 0.4815 - val_loss: 1.6494 - val_acc: 0.4792\n",
      "\n",
      "Epoch 791/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 38us/step - loss: 1.2046 - acc: 0.5463 - val_loss: 1.6570 - val_acc: 0.5000\n",
      "\n",
      "Epoch 792/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 46us/step - loss: 1.3544 - acc: 0.5000 - val_loss: 1.6570 - val_acc: 0.5000\n",
      "\n",
      "Epoch 793/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 35us/step - loss: 1.3777 - acc: 0.4583 - val_loss: 1.6549 - val_acc: 0.5000\n",
      "\n",
      "Epoch 794/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 35us/step - loss: 1.2335 - acc: 0.5694 - val_loss: 1.6494 - val_acc: 0.5000\n",
      "\n",
      "Epoch 795/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 33us/step - loss: 1.3962 - acc: 0.4722 - val_loss: 1.6477 - val_acc: 0.4792\n",
      "\n",
      "Epoch 796/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 33us/step - loss: 1.2302 - acc: 0.5694 - val_loss: 1.6610 - val_acc: 0.5000\n",
      "\n",
      "Epoch 797/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 34us/step - loss: 1.3502 - acc: 0.4861 - val_loss: 1.6664 - val_acc: 0.4583\n",
      "\n",
      "Epoch 798/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 34us/step - loss: 1.2401 - acc: 0.5139 - val_loss: 1.6712 - val_acc: 0.4792\n",
      "\n",
      "Epoch 799/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 36us/step - loss: 1.2591 - acc: 0.5509 - val_loss: 1.6832 - val_acc: 0.4792\n",
      "\n",
      "Epoch 800/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 36us/step - loss: 1.3046 - acc: 0.5046 - val_loss: 1.6666 - val_acc: 0.4792\n",
      "\n",
      "Epoch 801/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 35us/step - loss: 1.3310 - acc: 0.5694 - val_loss: 1.6772 - val_acc: 0.4792\n",
      "\n",
      "Epoch 802/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 45us/step - loss: 1.3363 - acc: 0.4815 - val_loss: 1.6506 - val_acc: 0.4792\n",
      "\n",
      "Epoch 803/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 34us/step - loss: 1.2711 - acc: 0.5463 - val_loss: 1.6546 - val_acc: 0.4792\n",
      "\n",
      "Epoch 804/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 35us/step - loss: 1.4040 - acc: 0.4537 - val_loss: 1.6686 - val_acc: 0.4792\n",
      "\n",
      "Epoch 805/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 32us/step - loss: 1.3061 - acc: 0.5000 - val_loss: 1.6607 - val_acc: 0.4792\n",
      "\n",
      "Epoch 806/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 31us/step - loss: 1.3205 - acc: 0.5370 - val_loss: 1.6559 - val_acc: 0.4792\n",
      "\n",
      "Epoch 807/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 35us/step - loss: 1.2352 - acc: 0.5556 - val_loss: 1.6654 - val_acc: 0.4792\n",
      "\n",
      "Epoch 808/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 40us/step - loss: 1.2483 - acc: 0.5093 - val_loss: 1.6620 - val_acc: 0.4583\n",
      "\n",
      "Epoch 809/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 38us/step - loss: 1.3275 - acc: 0.4769 - val_loss: 1.6607 - val_acc: 0.4792\n",
      "\n",
      "Epoch 810/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 40us/step - loss: 1.3077 - acc: 0.5093 - val_loss: 1.6594 - val_acc: 0.5208\n",
      "\n",
      "Epoch 811/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 34us/step - loss: 1.2691 - acc: 0.5324 - val_loss: 1.6702 - val_acc: 0.5000\n",
      "\n",
      "Epoch 812/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 35us/step - loss: 1.3183 - acc: 0.5000 - val_loss: 1.6707 - val_acc: 0.5000\n",
      "\n",
      "Epoch 813/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 38us/step - loss: 1.3283 - acc: 0.5093 - val_loss: 1.6603 - val_acc: 0.4792\n",
      "\n",
      "Epoch 814/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 37us/step - loss: 1.3193 - acc: 0.4954 - val_loss: 1.6663 - val_acc: 0.5000\n",
      "\n",
      "Epoch 815/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 33us/step - loss: 1.2848 - acc: 0.5093 - val_loss: 1.6562 - val_acc: 0.4792\n",
      "\n",
      "Epoch 816/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 35us/step - loss: 1.2799 - acc: 0.5278 - val_loss: 1.6609 - val_acc: 0.4792\n",
      "\n",
      "Epoch 817/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 46us/step - loss: 1.2359 - acc: 0.5463 - val_loss: 1.6720 - val_acc: 0.4792\n",
      "\n",
      "Epoch 818/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 33us/step - loss: 1.2947 - acc: 0.5231 - val_loss: 1.6682 - val_acc: 0.4792\n",
      "\n",
      "Epoch 819/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 39us/step - loss: 1.2613 - acc: 0.5648 - val_loss: 1.6692 - val_acc: 0.4792\n",
      "\n",
      "Epoch 820/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 37us/step - loss: 1.2893 - acc: 0.5278 - val_loss: 1.6622 - val_acc: 0.5000\n",
      "\n",
      "Epoch 821/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 40us/step - loss: 1.2914 - acc: 0.5370 - val_loss: 1.6640 - val_acc: 0.4583\n",
      "\n",
      "Epoch 822/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 40us/step - loss: 1.3505 - acc: 0.5046 - val_loss: 1.6584 - val_acc: 0.4792\n",
      "\n",
      "Epoch 823/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 43us/step - loss: 1.2822 - acc: 0.5139 - val_loss: 1.6604 - val_acc: 0.4792\n",
      "\n",
      "Epoch 824/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 35us/step - loss: 1.2756 - acc: 0.5139 - val_loss: 1.6616 - val_acc: 0.5000\n",
      "\n",
      "Epoch 825/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 32us/step - loss: 1.2521 - acc: 0.4954 - val_loss: 1.6748 - val_acc: 0.4792\n",
      "\n",
      "Epoch 826/1200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "216/216 [==============================]216/216 [==============================] - 0s 36us/step - loss: 1.3128 - acc: 0.5093 - val_loss: 1.6790 - val_acc: 0.4583\n",
      "\n",
      "Epoch 827/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 41us/step - loss: 1.2338 - acc: 0.5000 - val_loss: 1.6754 - val_acc: 0.4583\n",
      "\n",
      "Epoch 828/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 32us/step - loss: 1.3102 - acc: 0.4676 - val_loss: 1.6743 - val_acc: 0.4583\n",
      "\n",
      "Epoch 829/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 36us/step - loss: 1.2338 - acc: 0.5556 - val_loss: 1.6749 - val_acc: 0.5000\n",
      "\n",
      "Epoch 830/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 35us/step - loss: 1.2552 - acc: 0.5463 - val_loss: 1.6820 - val_acc: 0.4583\n",
      "\n",
      "Epoch 831/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 40us/step - loss: 1.2976 - acc: 0.5000 - val_loss: 1.6750 - val_acc: 0.4583\n",
      "\n",
      "Epoch 832/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 41us/step - loss: 1.2750 - acc: 0.4954 - val_loss: 1.6762 - val_acc: 0.4792\n",
      "\n",
      "Epoch 833/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 37us/step - loss: 1.2470 - acc: 0.5278 - val_loss: 1.6832 - val_acc: 0.4583\n",
      "\n",
      "Epoch 834/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 40us/step - loss: 1.2901 - acc: 0.5093 - val_loss: 1.6737 - val_acc: 0.5000\n",
      "\n",
      "Epoch 835/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 74us/step - loss: 1.2483 - acc: 0.5046 - val_loss: 1.6775 - val_acc: 0.4792\n",
      "\n",
      "Epoch 836/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 38us/step - loss: 1.3107 - acc: 0.5185 - val_loss: 1.6731 - val_acc: 0.4792\n",
      "\n",
      "Epoch 837/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 36us/step - loss: 1.3288 - acc: 0.5324 - val_loss: 1.6727 - val_acc: 0.4792\n",
      "\n",
      "Epoch 838/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 34us/step - loss: 1.2794 - acc: 0.4769 - val_loss: 1.6770 - val_acc: 0.5000\n",
      "\n",
      "Epoch 839/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 46us/step - loss: 1.2988 - acc: 0.5370 - val_loss: 1.6828 - val_acc: 0.4792\n",
      "\n",
      "Epoch 840/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 40us/step - loss: 1.2411 - acc: 0.5509 - val_loss: 1.6809 - val_acc: 0.5000\n",
      "\n",
      "Epoch 841/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 39us/step - loss: 1.3327 - acc: 0.4954 - val_loss: 1.6731 - val_acc: 0.5000\n",
      "\n",
      "Epoch 842/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 49us/step - loss: 1.2775 - acc: 0.5139 - val_loss: 1.6790 - val_acc: 0.4792\n",
      "\n",
      "Epoch 843/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 170us/step - loss: 1.2988 - acc: 0.5278 - val_loss: 1.6685 - val_acc: 0.5000\n",
      "\n",
      "Epoch 844/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 80us/step - loss: 1.2149 - acc: 0.5741 - val_loss: 1.6791 - val_acc: 0.5000\n",
      "\n",
      "Epoch 845/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 106us/step - loss: 1.2793 - acc: 0.4861 - val_loss: 1.6731 - val_acc: 0.5000\n",
      "\n",
      "Epoch 846/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 107us/step - loss: 1.3106 - acc: 0.5139 - val_loss: 1.6731 - val_acc: 0.4792\n",
      "\n",
      "Epoch 847/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 110us/step - loss: 1.2686 - acc: 0.5324 - val_loss: 1.6743 - val_acc: 0.4792\n",
      "\n",
      "Epoch 848/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 101us/step - loss: 1.2343 - acc: 0.5463 - val_loss: 1.6750 - val_acc: 0.5000\n",
      "\n",
      "Epoch 849/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 105us/step - loss: 1.2248 - acc: 0.5694 - val_loss: 1.6772 - val_acc: 0.5000\n",
      "\n",
      "Epoch 850/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 180us/step - loss: 1.2956 - acc: 0.5046 - val_loss: 1.6848 - val_acc: 0.5000\n",
      "\n",
      "Epoch 851/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 95us/step - loss: 1.2648 - acc: 0.5139 - val_loss: 1.6803 - val_acc: 0.4792\n",
      "\n",
      "Epoch 852/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 107us/step - loss: 1.2804 - acc: 0.5509 - val_loss: 1.6895 - val_acc: 0.4583\n",
      "\n",
      "Epoch 853/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 110us/step - loss: 1.2555 - acc: 0.5602 - val_loss: 1.6894 - val_acc: 0.4792\n",
      "\n",
      "Epoch 854/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 102us/step - loss: 1.2637 - acc: 0.5231 - val_loss: 1.6863 - val_acc: 0.4583\n",
      "\n",
      "Epoch 855/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 93us/step - loss: 1.2428 - acc: 0.5556 - val_loss: 1.6728 - val_acc: 0.4583\n",
      "\n",
      "Epoch 856/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 107us/step - loss: 1.2928 - acc: 0.5231 - val_loss: 1.6767 - val_acc: 0.4792\n",
      "\n",
      "Epoch 857/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 86us/step - loss: 1.2783 - acc: 0.5602 - val_loss: 1.6772 - val_acc: 0.5000\n",
      "\n",
      "Epoch 858/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 114us/step - loss: 1.2443 - acc: 0.5231 - val_loss: 1.6721 - val_acc: 0.5000\n",
      "\n",
      "Epoch 859/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 83us/step - loss: 1.2942 - acc: 0.5139 - val_loss: 1.6695 - val_acc: 0.5000\n",
      "\n",
      "Epoch 860/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 111us/step - loss: 1.2943 - acc: 0.5278 - val_loss: 1.6785 - val_acc: 0.5000\n",
      "\n",
      "Epoch 861/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 94us/step - loss: 1.2051 - acc: 0.5417 - val_loss: 1.6736 - val_acc: 0.5000\n",
      "\n",
      "Epoch 862/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 95us/step - loss: 1.2783 - acc: 0.5278 - val_loss: 1.6729 - val_acc: 0.5000\n",
      "\n",
      "Epoch 863/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 82us/step - loss: 1.2880 - acc: 0.5093 - val_loss: 1.6800 - val_acc: 0.5000\n",
      "\n",
      "Epoch 864/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 103us/step - loss: 1.2996 - acc: 0.5370 - val_loss: 1.6801 - val_acc: 0.4792\n",
      "\n",
      "Epoch 865/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 81us/step - loss: 1.2595 - acc: 0.5648 - val_loss: 1.6908 - val_acc: 0.4792\n",
      "\n",
      "Epoch 866/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 97us/step - loss: 1.2497 - acc: 0.5231 - val_loss: 1.6940 - val_acc: 0.4792\n",
      "\n",
      "Epoch 867/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 112us/step - loss: 1.2164 - acc: 0.5556 - val_loss: 1.6995 - val_acc: 0.4792\n",
      "\n",
      "Epoch 868/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 150us/step - loss: 1.3133 - acc: 0.4769 - val_loss: 1.6816 - val_acc: 0.4792\n",
      "\n",
      "Epoch 869/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 118us/step - loss: 1.2793 - acc: 0.4954 - val_loss: 1.6739 - val_acc: 0.5000\n",
      "\n",
      "Epoch 870/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 102us/step - loss: 1.2860 - acc: 0.5509 - val_loss: 1.6792 - val_acc: 0.5000\n",
      "\n",
      "Epoch 871/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 114us/step - loss: 1.2700 - acc: 0.5463 - val_loss: 1.6918 - val_acc: 0.4583\n",
      "\n",
      "Epoch 872/1200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "216/216 [==============================]216/216 [==============================] - 0s 109us/step - loss: 1.3037 - acc: 0.4954 - val_loss: 1.6934 - val_acc: 0.5000\n",
      "\n",
      "Epoch 873/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 115us/step - loss: 1.2836 - acc: 0.4815 - val_loss: 1.6934 - val_acc: 0.4792\n",
      "\n",
      "Epoch 874/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 115us/step - loss: 1.2771 - acc: 0.5417 - val_loss: 1.6928 - val_acc: 0.5000\n",
      "\n",
      "Epoch 875/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 166us/step - loss: 1.2866 - acc: 0.5370 - val_loss: 1.6867 - val_acc: 0.4792\n",
      "\n",
      "Epoch 876/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 107us/step - loss: 1.3187 - acc: 0.4954 - val_loss: 1.6875 - val_acc: 0.5000\n",
      "\n",
      "Epoch 877/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 106us/step - loss: 1.2981 - acc: 0.4861 - val_loss: 1.6697 - val_acc: 0.4792\n",
      "\n",
      "Epoch 878/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 123us/step - loss: 1.3328 - acc: 0.5000 - val_loss: 1.6692 - val_acc: 0.5000\n",
      "\n",
      "Epoch 879/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 99us/step - loss: 1.1982 - acc: 0.5833 - val_loss: 1.6765 - val_acc: 0.4583\n",
      "\n",
      "Epoch 880/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 102us/step - loss: 1.2924 - acc: 0.5231 - val_loss: 1.6702 - val_acc: 0.4792\n",
      "\n",
      "Epoch 881/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 121us/step - loss: 1.2428 - acc: 0.5000 - val_loss: 1.6807 - val_acc: 0.5000\n",
      "\n",
      "Epoch 882/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 85us/step - loss: 1.2488 - acc: 0.5278 - val_loss: 1.6879 - val_acc: 0.4792\n",
      "\n",
      "Epoch 883/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 82us/step - loss: 1.2983 - acc: 0.5324 - val_loss: 1.6886 - val_acc: 0.4792\n",
      "\n",
      "Epoch 884/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 108us/step - loss: 1.2256 - acc: 0.5556 - val_loss: 1.6764 - val_acc: 0.4583\n",
      "\n",
      "Epoch 885/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 96us/step - loss: 1.2773 - acc: 0.5556 - val_loss: 1.6864 - val_acc: 0.4583\n",
      "\n",
      "Epoch 886/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 107us/step - loss: 1.2966 - acc: 0.5000 - val_loss: 1.6876 - val_acc: 0.4792\n",
      "\n",
      "Epoch 887/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 96us/step - loss: 1.2290 - acc: 0.5741 - val_loss: 1.7041 - val_acc: 0.4792\n",
      "\n",
      "Epoch 888/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 87us/step - loss: 1.3188 - acc: 0.5139 - val_loss: 1.6868 - val_acc: 0.4792\n",
      "\n",
      "Epoch 889/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 85us/step - loss: 1.2477 - acc: 0.5417 - val_loss: 1.6973 - val_acc: 0.5000\n",
      "\n",
      "Epoch 890/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 88us/step - loss: 1.2347 - acc: 0.5324 - val_loss: 1.6954 - val_acc: 0.5000\n",
      "\n",
      "Epoch 891/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 78us/step - loss: 1.2392 - acc: 0.5463 - val_loss: 1.6952 - val_acc: 0.5000\n",
      "\n",
      "Epoch 892/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 92us/step - loss: 1.2929 - acc: 0.5185 - val_loss: 1.6888 - val_acc: 0.5000\n",
      "\n",
      "Epoch 893/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 92us/step - loss: 1.3145 - acc: 0.5185 - val_loss: 1.6839 - val_acc: 0.5000\n",
      "\n",
      "Epoch 894/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 94us/step - loss: 1.2788 - acc: 0.5509 - val_loss: 1.6888 - val_acc: 0.5000\n",
      "\n",
      "Epoch 895/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 79us/step - loss: 1.2831 - acc: 0.5463 - val_loss: 1.6889 - val_acc: 0.5000\n",
      "\n",
      "Epoch 896/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 57us/step - loss: 1.2681 - acc: 0.5370 - val_loss: 1.6874 - val_acc: 0.4792\n",
      "\n",
      "Epoch 897/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 37us/step - loss: 1.2325 - acc: 0.5463 - val_loss: 1.6804 - val_acc: 0.5000\n",
      "\n",
      "Epoch 898/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 33us/step - loss: 1.1599 - acc: 0.6343 - val_loss: 1.6924 - val_acc: 0.4792\n",
      "\n",
      "Epoch 899/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 38us/step - loss: 1.2793 - acc: 0.4954 - val_loss: 1.6845 - val_acc: 0.5000\n",
      "\n",
      "Epoch 900/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 34us/step - loss: 1.2655 - acc: 0.5463 - val_loss: 1.6775 - val_acc: 0.5000\n",
      "\n",
      "Epoch 901/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 34us/step - loss: 1.1715 - acc: 0.5648 - val_loss: 1.6796 - val_acc: 0.5000\n",
      "\n",
      "Epoch 902/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 34us/step - loss: 1.1990 - acc: 0.5880 - val_loss: 1.6832 - val_acc: 0.5000\n",
      "\n",
      "Epoch 903/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 34us/step - loss: 1.2997 - acc: 0.5231 - val_loss: 1.6877 - val_acc: 0.5000\n",
      "\n",
      "Epoch 904/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 33us/step - loss: 1.2423 - acc: 0.5509 - val_loss: 1.6951 - val_acc: 0.5000\n",
      "\n",
      "Epoch 905/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 39us/step - loss: 1.2918 - acc: 0.5046 - val_loss: 1.6977 - val_acc: 0.4792\n",
      "\n",
      "Epoch 906/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 34us/step - loss: 1.2782 - acc: 0.5093 - val_loss: 1.6932 - val_acc: 0.5000\n",
      "\n",
      "Epoch 907/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 34us/step - loss: 1.2946 - acc: 0.5509 - val_loss: 1.6938 - val_acc: 0.5000\n",
      "\n",
      "Epoch 908/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 36us/step - loss: 1.2252 - acc: 0.5417 - val_loss: 1.6942 - val_acc: 0.4792\n",
      "\n",
      "Epoch 909/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 37us/step - loss: 1.2729 - acc: 0.5370 - val_loss: 1.6926 - val_acc: 0.5000\n",
      "\n",
      "Epoch 910/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 33us/step - loss: 1.2829 - acc: 0.5278 - val_loss: 1.6948 - val_acc: 0.5000\n",
      "\n",
      "Epoch 911/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 38us/step - loss: 1.2523 - acc: 0.5556 - val_loss: 1.6927 - val_acc: 0.5000\n",
      "\n",
      "Epoch 912/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 41us/step - loss: 1.2950 - acc: 0.4907 - val_loss: 1.6930 - val_acc: 0.5000\n",
      "\n",
      "Epoch 913/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 41us/step - loss: 1.1897 - acc: 0.5694 - val_loss: 1.6994 - val_acc: 0.5000\n",
      "\n",
      "Epoch 914/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 48us/step - loss: 1.2505 - acc: 0.5556 - val_loss: 1.6990 - val_acc: 0.5000\n",
      "\n",
      "Epoch 915/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 37us/step - loss: 1.2057 - acc: 0.5741 - val_loss: 1.6999 - val_acc: 0.5000\n",
      "\n",
      "Epoch 916/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 35us/step - loss: 1.2329 - acc: 0.5463 - val_loss: 1.7042 - val_acc: 0.5000\n",
      "\n",
      "Epoch 917/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 38us/step - loss: 1.2829 - acc: 0.5324 - val_loss: 1.6922 - val_acc: 0.5000\n",
      "\n",
      "Epoch 918/1200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "216/216 [==============================]216/216 [==============================] - 0s 36us/step - loss: 1.3154 - acc: 0.5185 - val_loss: 1.6945 - val_acc: 0.5000\n",
      "\n",
      "Epoch 919/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 39us/step - loss: 1.2837 - acc: 0.5046 - val_loss: 1.6941 - val_acc: 0.5000\n",
      "\n",
      "Epoch 920/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 37us/step - loss: 1.2451 - acc: 0.5509 - val_loss: 1.6867 - val_acc: 0.4792\n",
      "\n",
      "Epoch 921/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 37us/step - loss: 1.3143 - acc: 0.5093 - val_loss: 1.6904 - val_acc: 0.4792\n",
      "\n",
      "Epoch 922/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 34us/step - loss: 1.2080 - acc: 0.5463 - val_loss: 1.6858 - val_acc: 0.4792\n",
      "\n",
      "Epoch 923/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 40us/step - loss: 1.1809 - acc: 0.5880 - val_loss: 1.6940 - val_acc: 0.4792\n",
      "\n",
      "Epoch 924/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 33us/step - loss: 1.2912 - acc: 0.5370 - val_loss: 1.6824 - val_acc: 0.5000\n",
      "\n",
      "Epoch 925/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 40us/step - loss: 1.2114 - acc: 0.5556 - val_loss: 1.6895 - val_acc: 0.5000\n",
      "\n",
      "Epoch 926/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 37us/step - loss: 1.3190 - acc: 0.4907 - val_loss: 1.6895 - val_acc: 0.5000\n",
      "\n",
      "Epoch 927/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 48us/step - loss: 1.4018 - acc: 0.4954 - val_loss: 1.6800 - val_acc: 0.5000\n",
      "\n",
      "Epoch 928/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 33us/step - loss: 1.2409 - acc: 0.5417 - val_loss: 1.6841 - val_acc: 0.5000\n",
      "\n",
      "Epoch 929/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 33us/step - loss: 1.2053 - acc: 0.5880 - val_loss: 1.6964 - val_acc: 0.5000\n",
      "\n",
      "Epoch 930/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 38us/step - loss: 1.2437 - acc: 0.5324 - val_loss: 1.6915 - val_acc: 0.5000\n",
      "\n",
      "Epoch 931/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 41us/step - loss: 1.2802 - acc: 0.5602 - val_loss: 1.6986 - val_acc: 0.5000\n",
      "\n",
      "Epoch 932/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 34us/step - loss: 1.3082 - acc: 0.5231 - val_loss: 1.6915 - val_acc: 0.5000\n",
      "\n",
      "Epoch 933/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 33us/step - loss: 1.2612 - acc: 0.5417 - val_loss: 1.6898 - val_acc: 0.5000\n",
      "\n",
      "Epoch 934/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 33us/step - loss: 1.2243 - acc: 0.5370 - val_loss: 1.6967 - val_acc: 0.5000\n",
      "\n",
      "Epoch 935/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 34us/step - loss: 1.2697 - acc: 0.5231 - val_loss: 1.7007 - val_acc: 0.4792\n",
      "\n",
      "Epoch 936/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 31us/step - loss: 1.2378 - acc: 0.4954 - val_loss: 1.7090 - val_acc: 0.5000\n",
      "\n",
      "Epoch 937/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 33us/step - loss: 1.2641 - acc: 0.5417 - val_loss: 1.7014 - val_acc: 0.5000\n",
      "\n",
      "Epoch 938/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 37us/step - loss: 1.2056 - acc: 0.5972 - val_loss: 1.7020 - val_acc: 0.5000\n",
      "\n",
      "Epoch 939/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 34us/step - loss: 1.2760 - acc: 0.5278 - val_loss: 1.6924 - val_acc: 0.5000\n",
      "\n",
      "Epoch 940/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 34us/step - loss: 1.2390 - acc: 0.5463 - val_loss: 1.6959 - val_acc: 0.5000\n",
      "\n",
      "Epoch 941/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 36us/step - loss: 1.2893 - acc: 0.4861 - val_loss: 1.6922 - val_acc: 0.5000\n",
      "\n",
      "Epoch 942/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 39us/step - loss: 1.2594 - acc: 0.5694 - val_loss: 1.6957 - val_acc: 0.5000\n",
      "\n",
      "Epoch 943/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 39us/step - loss: 1.2498 - acc: 0.5324 - val_loss: 1.7039 - val_acc: 0.5000\n",
      "\n",
      "Epoch 944/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 38us/step - loss: 1.2765 - acc: 0.5185 - val_loss: 1.7030 - val_acc: 0.5000\n",
      "\n",
      "Epoch 945/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 43us/step - loss: 1.2172 - acc: 0.5741 - val_loss: 1.7025 - val_acc: 0.4792\n",
      "\n",
      "Epoch 946/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 40us/step - loss: 1.2582 - acc: 0.5324 - val_loss: 1.7015 - val_acc: 0.5000\n",
      "\n",
      "Epoch 947/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 38us/step - loss: 1.2670 - acc: 0.5324 - val_loss: 1.6938 - val_acc: 0.5000\n",
      "\n",
      "Epoch 948/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 45us/step - loss: 1.2791 - acc: 0.5370 - val_loss: 1.6850 - val_acc: 0.4792\n",
      "\n",
      "Epoch 949/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 38us/step - loss: 1.2255 - acc: 0.5370 - val_loss: 1.6957 - val_acc: 0.4792\n",
      "\n",
      "Epoch 950/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 48us/step - loss: 1.2367 - acc: 0.5509 - val_loss: 1.6989 - val_acc: 0.5000\n",
      "\n",
      "Epoch 951/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 53us/step - loss: 1.1829 - acc: 0.5833 - val_loss: 1.7019 - val_acc: 0.5000\n",
      "\n",
      "Epoch 952/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 51us/step - loss: 1.3279 - acc: 0.5139 - val_loss: 1.7056 - val_acc: 0.4792\n",
      "\n",
      "Epoch 953/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 53us/step - loss: 1.2826 - acc: 0.5278 - val_loss: 1.6931 - val_acc: 0.5000\n",
      "\n",
      "Epoch 954/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 52us/step - loss: 1.2790 - acc: 0.5833 - val_loss: 1.6964 - val_acc: 0.5000\n",
      "\n",
      "Epoch 955/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 98us/step - loss: 1.2487 - acc: 0.5278 - val_loss: 1.6946 - val_acc: 0.5000\n",
      "\n",
      "Epoch 956/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 94us/step - loss: 1.2650 - acc: 0.5741 - val_loss: 1.6936 - val_acc: 0.4792\n",
      "\n",
      "Epoch 957/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 224us/step - loss: 1.2349 - acc: 0.5556 - val_loss: 1.6984 - val_acc: 0.4792\n",
      "\n",
      "Epoch 958/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 109us/step - loss: 1.2309 - acc: 0.5787 - val_loss: 1.6970 - val_acc: 0.5000\n",
      "\n",
      "Epoch 959/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 100us/step - loss: 1.2613 - acc: 0.5185 - val_loss: 1.7132 - val_acc: 0.5000\n",
      "\n",
      "Epoch 960/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 100us/step - loss: 1.2805 - acc: 0.5417 - val_loss: 1.7006 - val_acc: 0.5000\n",
      "\n",
      "Epoch 961/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 116us/step - loss: 1.2366 - acc: 0.5463 - val_loss: 1.6972 - val_acc: 0.5000\n",
      "\n",
      "Epoch 962/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 105us/step - loss: 1.2910 - acc: 0.4815 - val_loss: 1.6966 - val_acc: 0.5000\n",
      "\n",
      "Epoch 963/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 103us/step - loss: 1.2257 - acc: 0.5185 - val_loss: 1.7054 - val_acc: 0.5000\n",
      "\n",
      "Epoch 964/1200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "216/216 [==============================]216/216 [==============================] - 0s 106us/step - loss: 1.2722 - acc: 0.5093 - val_loss: 1.6972 - val_acc: 0.5000\n",
      "\n",
      "Epoch 965/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 105us/step - loss: 1.2613 - acc: 0.5463 - val_loss: 1.6949 - val_acc: 0.5000\n",
      "\n",
      "Epoch 966/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 106us/step - loss: 1.2473 - acc: 0.5694 - val_loss: 1.6982 - val_acc: 0.4792\n",
      "\n",
      "Epoch 967/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 110us/step - loss: 1.2649 - acc: 0.5417 - val_loss: 1.7062 - val_acc: 0.5000\n",
      "\n",
      "Epoch 968/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 110us/step - loss: 1.1589 - acc: 0.6065 - val_loss: 1.7039 - val_acc: 0.5000\n",
      "\n",
      "Epoch 969/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 105us/step - loss: 1.2717 - acc: 0.5231 - val_loss: 1.6985 - val_acc: 0.5000\n",
      "\n",
      "Epoch 970/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 227us/step - loss: 1.2440 - acc: 0.5278 - val_loss: 1.7013 - val_acc: 0.5000\n",
      "\n",
      "Epoch 971/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 100us/step - loss: 1.3133 - acc: 0.5231 - val_loss: 1.6946 - val_acc: 0.5000\n",
      "\n",
      "Epoch 972/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 105us/step - loss: 1.1968 - acc: 0.5417 - val_loss: 1.7056 - val_acc: 0.5000\n",
      "\n",
      "Epoch 973/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 105us/step - loss: 1.2305 - acc: 0.5741 - val_loss: 1.7121 - val_acc: 0.5000\n",
      "\n",
      "Epoch 974/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 137us/step - loss: 1.1415 - acc: 0.5833 - val_loss: 1.7149 - val_acc: 0.5000\n",
      "\n",
      "Epoch 975/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 115us/step - loss: 1.2412 - acc: 0.4907 - val_loss: 1.6987 - val_acc: 0.5000\n",
      "\n",
      "Epoch 976/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 98us/step - loss: 1.1341 - acc: 0.6204 - val_loss: 1.6955 - val_acc: 0.5000\n",
      "\n",
      "Epoch 977/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 96us/step - loss: 1.2561 - acc: 0.5370 - val_loss: 1.7061 - val_acc: 0.5000\n",
      "\n",
      "Epoch 978/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 112us/step - loss: 1.2347 - acc: 0.5417 - val_loss: 1.7085 - val_acc: 0.5000\n",
      "\n",
      "Epoch 979/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 119us/step - loss: 1.1519 - acc: 0.5972 - val_loss: 1.7212 - val_acc: 0.5000\n",
      "\n",
      "Epoch 980/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 151us/step - loss: 1.2355 - acc: 0.5509 - val_loss: 1.7168 - val_acc: 0.5000\n",
      "\n",
      "Epoch 981/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 86us/step - loss: 1.2665 - acc: 0.4907 - val_loss: 1.7195 - val_acc: 0.5000\n",
      "\n",
      "Epoch 982/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 86us/step - loss: 1.2543 - acc: 0.5139 - val_loss: 1.7211 - val_acc: 0.5000\n",
      "\n",
      "Epoch 983/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 83us/step - loss: 1.2691 - acc: 0.5185 - val_loss: 1.7164 - val_acc: 0.5000\n",
      "\n",
      "Epoch 984/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 102us/step - loss: 1.2351 - acc: 0.5556 - val_loss: 1.7182 - val_acc: 0.5000\n",
      "\n",
      "Epoch 985/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 101us/step - loss: 1.2806 - acc: 0.5417 - val_loss: 1.7130 - val_acc: 0.5000\n",
      "\n",
      "Epoch 986/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 85us/step - loss: 1.1766 - acc: 0.5648 - val_loss: 1.7100 - val_acc: 0.5000\n",
      "\n",
      "Epoch 987/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 94us/step - loss: 1.2652 - acc: 0.5463 - val_loss: 1.7171 - val_acc: 0.5000\n",
      "\n",
      "Epoch 988/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 82us/step - loss: 1.2688 - acc: 0.5093 - val_loss: 1.7085 - val_acc: 0.5000\n",
      "\n",
      "Epoch 989/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 143us/step - loss: 1.2120 - acc: 0.5741 - val_loss: 1.6982 - val_acc: 0.5000\n",
      "\n",
      "Epoch 990/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 86us/step - loss: 1.2297 - acc: 0.5370 - val_loss: 1.6912 - val_acc: 0.5000\n",
      "\n",
      "Epoch 991/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 106us/step - loss: 1.1803 - acc: 0.5741 - val_loss: 1.6974 - val_acc: 0.5000\n",
      "\n",
      "Epoch 992/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 92us/step - loss: 1.2524 - acc: 0.5231 - val_loss: 1.7003 - val_acc: 0.4792\n",
      "\n",
      "Epoch 993/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 119us/step - loss: 1.2278 - acc: 0.5556 - val_loss: 1.7001 - val_acc: 0.4792\n",
      "\n",
      "Epoch 994/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 85us/step - loss: 1.3249 - acc: 0.5231 - val_loss: 1.6985 - val_acc: 0.4792\n",
      "\n",
      "Epoch 995/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 80us/step - loss: 1.2475 - acc: 0.4954 - val_loss: 1.7063 - val_acc: 0.5000\n",
      "\n",
      "Epoch 996/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 83us/step - loss: 1.2029 - acc: 0.5741 - val_loss: 1.7096 - val_acc: 0.5000\n",
      "\n",
      "Epoch 997/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 93us/step - loss: 1.2517 - acc: 0.5324 - val_loss: 1.7121 - val_acc: 0.4792\n",
      "\n",
      "Epoch 998/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 93us/step - loss: 1.1700 - acc: 0.5926 - val_loss: 1.7193 - val_acc: 0.4792\n",
      "\n",
      "Epoch 999/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 96us/step - loss: 1.2363 - acc: 0.5741 - val_loss: 1.7188 - val_acc: 0.5000\n",
      "\n",
      "Epoch 1000/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 91us/step - loss: 1.3008 - acc: 0.5046 - val_loss: 1.7271 - val_acc: 0.5000\n",
      "\n",
      "Epoch 1001/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 90us/step - loss: 1.2310 - acc: 0.5602 - val_loss: 1.7260 - val_acc: 0.5000\n",
      "\n",
      "Epoch 1002/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 85us/step - loss: 1.2475 - acc: 0.5093 - val_loss: 1.7034 - val_acc: 0.5000\n",
      "\n",
      "Epoch 1003/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 85us/step - loss: 1.2388 - acc: 0.5648 - val_loss: 1.7015 - val_acc: 0.5000\n",
      "\n",
      "Epoch 1004/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 81us/step - loss: 1.2551 - acc: 0.5509 - val_loss: 1.7074 - val_acc: 0.5000\n",
      "\n",
      "Epoch 1005/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 95us/step - loss: 1.2439 - acc: 0.5324 - val_loss: 1.7008 - val_acc: 0.5000\n",
      "\n",
      "Epoch 1006/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 91us/step - loss: 1.2486 - acc: 0.5231 - val_loss: 1.7009 - val_acc: 0.5000\n",
      "\n",
      "Epoch 1007/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 90us/step - loss: 1.1549 - acc: 0.5880 - val_loss: 1.7145 - val_acc: 0.5000\n",
      "\n",
      "Epoch 1008/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 32us/step - loss: 1.2342 - acc: 0.5509 - val_loss: 1.7059 - val_acc: 0.5000\n",
      "\n",
      "Epoch 1009/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 35us/step - loss: 1.2841 - acc: 0.5370 - val_loss: 1.7068 - val_acc: 0.5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1010/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 34us/step - loss: 1.2153 - acc: 0.5602 - val_loss: 1.7158 - val_acc: 0.5000\n",
      "\n",
      "Epoch 1011/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 38us/step - loss: 1.2507 - acc: 0.5278 - val_loss: 1.7158 - val_acc: 0.5208\n",
      "\n",
      "Epoch 1012/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 35us/step - loss: 1.2111 - acc: 0.5648 - val_loss: 1.7106 - val_acc: 0.5000\n",
      "\n",
      "Epoch 1013/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 31us/step - loss: 1.1964 - acc: 0.5741 - val_loss: 1.7115 - val_acc: 0.5000\n",
      "\n",
      "Epoch 1014/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 34us/step - loss: 1.1945 - acc: 0.5278 - val_loss: 1.7155 - val_acc: 0.5000\n",
      "\n",
      "Epoch 1015/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 42us/step - loss: 1.2675 - acc: 0.5278 - val_loss: 1.7179 - val_acc: 0.5000\n",
      "\n",
      "Epoch 1016/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 34us/step - loss: 1.2305 - acc: 0.5509 - val_loss: 1.7143 - val_acc: 0.5000\n",
      "\n",
      "Epoch 1017/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 31us/step - loss: 1.2167 - acc: 0.5509 - val_loss: 1.7120 - val_acc: 0.5000\n",
      "\n",
      "Epoch 1018/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 33us/step - loss: 1.2427 - acc: 0.5139 - val_loss: 1.7230 - val_acc: 0.5000\n",
      "\n",
      "Epoch 1019/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 31us/step - loss: 1.2915 - acc: 0.5185 - val_loss: 1.7164 - val_acc: 0.5000\n",
      "\n",
      "Epoch 1020/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 34us/step - loss: 1.2521 - acc: 0.5231 - val_loss: 1.7145 - val_acc: 0.5000\n",
      "\n",
      "Epoch 1021/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 32us/step - loss: 1.2173 - acc: 0.5556 - val_loss: 1.7230 - val_acc: 0.5000\n",
      "\n",
      "Epoch 1022/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 37us/step - loss: 1.1573 - acc: 0.5694 - val_loss: 1.7294 - val_acc: 0.5000\n",
      "\n",
      "Epoch 1023/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 31us/step - loss: 1.1910 - acc: 0.5787 - val_loss: 1.7295 - val_acc: 0.5000\n",
      "\n",
      "Epoch 1024/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 39us/step - loss: 1.1398 - acc: 0.6019 - val_loss: 1.7315 - val_acc: 0.5000\n",
      "\n",
      "Epoch 1025/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 32us/step - loss: 1.3176 - acc: 0.5231 - val_loss: 1.7208 - val_acc: 0.5000\n",
      "\n",
      "Epoch 1026/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 33us/step - loss: 1.1861 - acc: 0.5370 - val_loss: 1.7318 - val_acc: 0.5000\n",
      "\n",
      "Epoch 1027/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 40us/step - loss: 1.2137 - acc: 0.5509 - val_loss: 1.7206 - val_acc: 0.5000\n",
      "\n",
      "Epoch 1028/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 108us/step - loss: 1.2592 - acc: 0.5093 - val_loss: 1.7266 - val_acc: 0.5000\n",
      "\n",
      "Epoch 1029/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 47us/step - loss: 1.2208 - acc: 0.5880 - val_loss: 1.7248 - val_acc: 0.5000\n",
      "\n",
      "Epoch 1030/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 37us/step - loss: 1.2466 - acc: 0.5370 - val_loss: 1.7300 - val_acc: 0.5208\n",
      "\n",
      "Epoch 1031/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 32us/step - loss: 1.2777 - acc: 0.5278 - val_loss: 1.7182 - val_acc: 0.5000\n",
      "\n",
      "Epoch 1032/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 35us/step - loss: 1.2441 - acc: 0.5417 - val_loss: 1.7182 - val_acc: 0.5000\n",
      "\n",
      "Epoch 1033/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 34us/step - loss: 1.2467 - acc: 0.5509 - val_loss: 1.7269 - val_acc: 0.5000\n",
      "\n",
      "Epoch 1034/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 33us/step - loss: 1.1652 - acc: 0.5741 - val_loss: 1.7299 - val_acc: 0.5000\n",
      "\n",
      "Epoch 1035/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 32us/step - loss: 1.2115 - acc: 0.5602 - val_loss: 1.7315 - val_acc: 0.5000\n",
      "\n",
      "Epoch 1036/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 34us/step - loss: 1.1833 - acc: 0.5880 - val_loss: 1.7325 - val_acc: 0.5000\n",
      "\n",
      "Epoch 1037/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 32us/step - loss: 1.1536 - acc: 0.5787 - val_loss: 1.7267 - val_acc: 0.5000\n",
      "\n",
      "Epoch 1038/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 34us/step - loss: 1.2625 - acc: 0.5556 - val_loss: 1.7216 - val_acc: 0.5000\n",
      "\n",
      "Epoch 1039/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 32us/step - loss: 1.2384 - acc: 0.5602 - val_loss: 1.7272 - val_acc: 0.5000\n",
      "\n",
      "Epoch 1040/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 31us/step - loss: 1.1563 - acc: 0.5648 - val_loss: 1.7438 - val_acc: 0.4792\n",
      "\n",
      "Epoch 1041/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 33us/step - loss: 1.3279 - acc: 0.5046 - val_loss: 1.7382 - val_acc: 0.5000\n",
      "\n",
      "Epoch 1042/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 38us/step - loss: 1.3066 - acc: 0.5139 - val_loss: 1.7301 - val_acc: 0.5000\n",
      "\n",
      "Epoch 1043/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 32us/step - loss: 1.1957 - acc: 0.5787 - val_loss: 1.7340 - val_acc: 0.5000\n",
      "\n",
      "Epoch 1044/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 31us/step - loss: 1.2460 - acc: 0.5463 - val_loss: 1.7345 - val_acc: 0.5000\n",
      "\n",
      "Epoch 1045/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 34us/step - loss: 1.1741 - acc: 0.5370 - val_loss: 1.7301 - val_acc: 0.5000\n",
      "\n",
      "Epoch 1046/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 32us/step - loss: 1.2396 - acc: 0.5556 - val_loss: 1.7257 - val_acc: 0.4792\n",
      "\n",
      "Epoch 1047/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 34us/step - loss: 1.2277 - acc: 0.5370 - val_loss: 1.7315 - val_acc: 0.5000\n",
      "\n",
      "Epoch 1048/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 32us/step - loss: 1.1600 - acc: 0.5556 - val_loss: 1.7329 - val_acc: 0.5000\n",
      "\n",
      "Epoch 1049/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 34us/step - loss: 1.2045 - acc: 0.5648 - val_loss: 1.7252 - val_acc: 0.5000\n",
      "\n",
      "Epoch 1050/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 32us/step - loss: 1.2852 - acc: 0.4954 - val_loss: 1.7347 - val_acc: 0.5000\n",
      "\n",
      "Epoch 1051/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 31us/step - loss: 1.2572 - acc: 0.5417 - val_loss: 1.7353 - val_acc: 0.5000\n",
      "\n",
      "Epoch 1052/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 33us/step - loss: 1.2000 - acc: 0.5463 - val_loss: 1.7300 - val_acc: 0.5000\n",
      "\n",
      "Epoch 1053/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 35us/step - loss: 1.1906 - acc: 0.5139 - val_loss: 1.7190 - val_acc: 0.5000\n",
      "\n",
      "Epoch 1054/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 33us/step - loss: 1.2091 - acc: 0.5463 - val_loss: 1.7154 - val_acc: 0.5000\n",
      "\n",
      "Epoch 1055/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 32us/step - loss: 1.2365 - acc: 0.5602 - val_loss: 1.7179 - val_acc: 0.5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1056/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 33us/step - loss: 1.1827 - acc: 0.5741 - val_loss: 1.7322 - val_acc: 0.5000\n",
      "\n",
      "Epoch 1057/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 35us/step - loss: 1.1581 - acc: 0.5741 - val_loss: 1.7458 - val_acc: 0.5000\n",
      "\n",
      "Epoch 1058/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 33us/step - loss: 1.1561 - acc: 0.5648 - val_loss: 1.7459 - val_acc: 0.5000\n",
      "\n",
      "Epoch 1059/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 36us/step - loss: 1.1406 - acc: 0.5463 - val_loss: 1.7479 - val_acc: 0.5000\n",
      "\n",
      "Epoch 1060/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 32us/step - loss: 1.2091 - acc: 0.5556 - val_loss: 1.7424 - val_acc: 0.5000\n",
      "\n",
      "Epoch 1061/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 33us/step - loss: 1.2255 - acc: 0.5231 - val_loss: 1.7541 - val_acc: 0.5000\n",
      "\n",
      "Epoch 1062/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 37us/step - loss: 1.2074 - acc: 0.5509 - val_loss: 1.7490 - val_acc: 0.5000\n",
      "\n",
      "Epoch 1063/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 42us/step - loss: 1.1917 - acc: 0.5787 - val_loss: 1.7497 - val_acc: 0.5000\n",
      "\n",
      "Epoch 1064/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 36us/step - loss: 1.2198 - acc: 0.5509 - val_loss: 1.7447 - val_acc: 0.4792\n",
      "\n",
      "Epoch 1065/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 34us/step - loss: 1.1727 - acc: 0.5880 - val_loss: 1.7452 - val_acc: 0.5000\n",
      "\n",
      "Epoch 1066/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 31us/step - loss: 1.2443 - acc: 0.5556 - val_loss: 1.7353 - val_acc: 0.5000\n",
      "\n",
      "Epoch 1067/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 31us/step - loss: 1.2817 - acc: 0.5417 - val_loss: 1.7350 - val_acc: 0.5000\n",
      "\n",
      "Epoch 1068/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 31us/step - loss: 1.2601 - acc: 0.5139 - val_loss: 1.7357 - val_acc: 0.5000\n",
      "\n",
      "Epoch 1069/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 38us/step - loss: 1.2419 - acc: 0.5556 - val_loss: 1.7393 - val_acc: 0.5000\n",
      "\n",
      "Epoch 1070/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 39us/step - loss: 1.2108 - acc: 0.5833 - val_loss: 1.7413 - val_acc: 0.5000\n",
      "\n",
      "Epoch 1071/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 36us/step - loss: 1.1264 - acc: 0.5741 - val_loss: 1.7441 - val_acc: 0.5000\n",
      "\n",
      "Epoch 1072/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 59us/step - loss: 1.2773 - acc: 0.5000 - val_loss: 1.7482 - val_acc: 0.5000\n",
      "\n",
      "Epoch 1073/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 162us/step - loss: 1.2496 - acc: 0.5694 - val_loss: 1.7388 - val_acc: 0.5000\n",
      "\n",
      "Epoch 1074/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 104us/step - loss: 1.2580 - acc: 0.5370 - val_loss: 1.7342 - val_acc: 0.5000\n",
      "\n",
      "Epoch 1075/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 105us/step - loss: 1.2361 - acc: 0.5694 - val_loss: 1.7466 - val_acc: 0.5000\n",
      "\n",
      "Epoch 1076/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 105us/step - loss: 1.1424 - acc: 0.6019 - val_loss: 1.7505 - val_acc: 0.5000\n",
      "\n",
      "Epoch 1077/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 106us/step - loss: 1.2168 - acc: 0.5509 - val_loss: 1.7379 - val_acc: 0.5000\n",
      "\n",
      "Epoch 1078/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 106us/step - loss: 1.1812 - acc: 0.5741 - val_loss: 1.7495 - val_acc: 0.5000\n",
      "\n",
      "Epoch 1079/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 105us/step - loss: 1.2230 - acc: 0.5972 - val_loss: 1.7511 - val_acc: 0.5000\n",
      "\n",
      "Epoch 1080/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 163us/step - loss: 1.2301 - acc: 0.5694 - val_loss: 1.7557 - val_acc: 0.5000\n",
      "\n",
      "Epoch 1081/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 94us/step - loss: 1.2220 - acc: 0.5278 - val_loss: 1.7635 - val_acc: 0.4792\n",
      "\n",
      "Epoch 1082/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 121us/step - loss: 1.2092 - acc: 0.5509 - val_loss: 1.7409 - val_acc: 0.5000\n",
      "\n",
      "Epoch 1083/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 100us/step - loss: 1.2743 - acc: 0.5556 - val_loss: 1.7440 - val_acc: 0.5000\n",
      "\n",
      "Epoch 1084/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 106us/step - loss: 1.2356 - acc: 0.5370 - val_loss: 1.7488 - val_acc: 0.5000\n",
      "\n",
      "Epoch 1085/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 126us/step - loss: 1.1835 - acc: 0.5833 - val_loss: 1.7658 - val_acc: 0.5000\n",
      "\n",
      "Epoch 1086/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 85us/step - loss: 1.2413 - acc: 0.5324 - val_loss: 1.7596 - val_acc: 0.4792\n",
      "\n",
      "Epoch 1087/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 119us/step - loss: 1.2125 - acc: 0.5741 - val_loss: 1.7696 - val_acc: 0.4792\n",
      "\n",
      "Epoch 1088/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 101us/step - loss: 1.2082 - acc: 0.5463 - val_loss: 1.7661 - val_acc: 0.5000\n",
      "\n",
      "Epoch 1089/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 171us/step - loss: 1.2076 - acc: 0.5648 - val_loss: 1.7586 - val_acc: 0.5000\n",
      "\n",
      "Epoch 1090/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 93us/step - loss: 1.2284 - acc: 0.5000 - val_loss: 1.7621 - val_acc: 0.4792\n",
      "\n",
      "Epoch 1091/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 108us/step - loss: 1.2687 - acc: 0.5509 - val_loss: 1.7491 - val_acc: 0.5000\n",
      "\n",
      "Epoch 1092/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 105us/step - loss: 1.1731 - acc: 0.5463 - val_loss: 1.7571 - val_acc: 0.5000\n",
      "\n",
      "Epoch 1093/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 106us/step - loss: 1.1877 - acc: 0.5602 - val_loss: 1.7548 - val_acc: 0.4792\n",
      "\n",
      "Epoch 1094/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 105us/step - loss: 1.2577 - acc: 0.5648 - val_loss: 1.7444 - val_acc: 0.4792\n",
      "\n",
      "Epoch 1095/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 106us/step - loss: 1.2120 - acc: 0.5648 - val_loss: 1.7439 - val_acc: 0.4792\n",
      "\n",
      "Epoch 1096/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 106us/step - loss: 1.2534 - acc: 0.5185 - val_loss: 1.7413 - val_acc: 0.5000\n",
      "\n",
      "Epoch 1097/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 147us/step - loss: 1.2622 - acc: 0.5787 - val_loss: 1.7448 - val_acc: 0.5000\n",
      "\n",
      "Epoch 1098/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 119us/step - loss: 1.2166 - acc: 0.5787 - val_loss: 1.7517 - val_acc: 0.5000\n",
      "\n",
      "Epoch 1099/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 100us/step - loss: 1.2088 - acc: 0.5556 - val_loss: 1.7482 - val_acc: 0.5000\n",
      "\n",
      "Epoch 1100/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 98us/step - loss: 1.2563 - acc: 0.5463 - val_loss: 1.7505 - val_acc: 0.5208\n",
      "\n",
      "Epoch 1101/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 98us/step - loss: 1.2002 - acc: 0.5648 - val_loss: 1.7519 - val_acc: 0.5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1102/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 124us/step - loss: 1.1865 - acc: 0.5648 - val_loss: 1.7576 - val_acc: 0.5000\n",
      "\n",
      "Epoch 1103/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 83us/step - loss: 1.1894 - acc: 0.5509 - val_loss: 1.7562 - val_acc: 0.5000\n",
      "\n",
      "Epoch 1104/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 120us/step - loss: 1.2461 - acc: 0.5139 - val_loss: 1.7532 - val_acc: 0.4792\n",
      "\n",
      "Epoch 1105/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 102us/step - loss: 1.1420 - acc: 0.5694 - val_loss: 1.7511 - val_acc: 0.5000\n",
      "\n",
      "Epoch 1106/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 134us/step - loss: 1.1955 - acc: 0.5417 - val_loss: 1.7564 - val_acc: 0.5000\n",
      "\n",
      "Epoch 1107/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 92us/step - loss: 1.2226 - acc: 0.5556 - val_loss: 1.7538 - val_acc: 0.5000\n",
      "\n",
      "Epoch 1108/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 98us/step - loss: 1.2086 - acc: 0.5926 - val_loss: 1.7476 - val_acc: 0.5000\n",
      "\n",
      "Epoch 1109/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 84us/step - loss: 1.1558 - acc: 0.5972 - val_loss: 1.7551 - val_acc: 0.5000\n",
      "\n",
      "Epoch 1110/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 103us/step - loss: 1.1906 - acc: 0.6065 - val_loss: 1.7542 - val_acc: 0.5000\n",
      "\n",
      "Epoch 1111/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 90us/step - loss: 1.2579 - acc: 0.5417 - val_loss: 1.7399 - val_acc: 0.5000\n",
      "\n",
      "Epoch 1112/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 102us/step - loss: 1.2320 - acc: 0.5231 - val_loss: 1.7342 - val_acc: 0.5000\n",
      "\n",
      "Epoch 1113/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 101us/step - loss: 1.3002 - acc: 0.5093 - val_loss: 1.7413 - val_acc: 0.5000\n",
      "\n",
      "Epoch 1114/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 106us/step - loss: 1.2597 - acc: 0.5370 - val_loss: 1.7510 - val_acc: 0.5000\n",
      "\n",
      "Epoch 1115/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 85us/step - loss: 1.2039 - acc: 0.5509 - val_loss: 1.7603 - val_acc: 0.5000\n",
      "\n",
      "Epoch 1116/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 101us/step - loss: 1.1795 - acc: 0.5417 - val_loss: 1.7600 - val_acc: 0.5000\n",
      "\n",
      "Epoch 1117/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 99us/step - loss: 1.2194 - acc: 0.5463 - val_loss: 1.7459 - val_acc: 0.5000\n",
      "\n",
      "Epoch 1118/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 84us/step - loss: 1.2267 - acc: 0.5463 - val_loss: 1.7513 - val_acc: 0.5000\n",
      "\n",
      "Epoch 1119/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 101us/step - loss: 1.2131 - acc: 0.5417 - val_loss: 1.7500 - val_acc: 0.5000\n",
      "\n",
      "Epoch 1120/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 116us/step - loss: 1.1757 - acc: 0.5231 - val_loss: 1.7489 - val_acc: 0.5000\n",
      "\n",
      "Epoch 1121/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 103us/step - loss: 1.2492 - acc: 0.5231 - val_loss: 1.7516 - val_acc: 0.4792\n",
      "\n",
      "Epoch 1122/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 86us/step - loss: 1.1870 - acc: 0.5370 - val_loss: 1.7497 - val_acc: 0.5000\n",
      "\n",
      "Epoch 1123/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 88us/step - loss: 1.2154 - acc: 0.5231 - val_loss: 1.7451 - val_acc: 0.5000\n",
      "\n",
      "Epoch 1124/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 75us/step - loss: 1.2273 - acc: 0.5417 - val_loss: 1.7543 - val_acc: 0.4792\n",
      "\n",
      "Epoch 1125/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 34us/step - loss: 1.2697 - acc: 0.5046 - val_loss: 1.7560 - val_acc: 0.5000\n",
      "\n",
      "Epoch 1126/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 31us/step - loss: 1.2391 - acc: 0.5556 - val_loss: 1.7506 - val_acc: 0.5000\n",
      "\n",
      "Epoch 1127/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 36us/step - loss: 1.1662 - acc: 0.5880 - val_loss: 1.7530 - val_acc: 0.5000\n",
      "\n",
      "Epoch 1128/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 39us/step - loss: 1.1559 - acc: 0.5556 - val_loss: 1.7568 - val_acc: 0.5000\n",
      "\n",
      "Epoch 1129/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 37us/step - loss: 1.1656 - acc: 0.5833 - val_loss: 1.7605 - val_acc: 0.5000\n",
      "\n",
      "Epoch 1130/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 34us/step - loss: 1.2687 - acc: 0.5324 - val_loss: 1.7646 - val_acc: 0.4792\n",
      "\n",
      "Epoch 1131/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 32us/step - loss: 1.1378 - acc: 0.5833 - val_loss: 1.7685 - val_acc: 0.4792\n",
      "\n",
      "Epoch 1132/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 35us/step - loss: 1.1975 - acc: 0.5417 - val_loss: 1.7536 - val_acc: 0.5000\n",
      "\n",
      "Epoch 1133/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 33us/step - loss: 1.1966 - acc: 0.5556 - val_loss: 1.7667 - val_acc: 0.5000\n",
      "\n",
      "Epoch 1134/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 33us/step - loss: 1.2132 - acc: 0.5556 - val_loss: 1.7662 - val_acc: 0.5000\n",
      "\n",
      "Epoch 1135/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 34us/step - loss: 1.1367 - acc: 0.5741 - val_loss: 1.7594 - val_acc: 0.5000\n",
      "\n",
      "Epoch 1136/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 41us/step - loss: 1.1463 - acc: 0.5278 - val_loss: 1.7513 - val_acc: 0.5000\n",
      "\n",
      "Epoch 1137/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 35us/step - loss: 1.1889 - acc: 0.6065 - val_loss: 1.7556 - val_acc: 0.5000\n",
      "\n",
      "Epoch 1138/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 31us/step - loss: 1.2042 - acc: 0.5602 - val_loss: 1.7610 - val_acc: 0.5000\n",
      "\n",
      "Epoch 1139/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 31us/step - loss: 1.2246 - acc: 0.5185 - val_loss: 1.7556 - val_acc: 0.5000\n",
      "\n",
      "Epoch 1140/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 34us/step - loss: 1.2072 - acc: 0.5694 - val_loss: 1.7685 - val_acc: 0.4792\n",
      "\n",
      "Epoch 1141/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 32us/step - loss: 1.2092 - acc: 0.5278 - val_loss: 1.7679 - val_acc: 0.5000\n",
      "\n",
      "Epoch 1142/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 35us/step - loss: 1.1787 - acc: 0.5880 - val_loss: 1.7747 - val_acc: 0.5000\n",
      "\n",
      "Epoch 1143/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 36us/step - loss: 1.2549 - acc: 0.5231 - val_loss: 1.7643 - val_acc: 0.5000\n",
      "\n",
      "Epoch 1144/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 31us/step - loss: 1.2255 - acc: 0.5509 - val_loss: 1.7690 - val_acc: 0.5000\n",
      "\n",
      "Epoch 1145/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 38us/step - loss: 1.1730 - acc: 0.5463 - val_loss: 1.7592 - val_acc: 0.5000\n",
      "\n",
      "Epoch 1146/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 36us/step - loss: 1.1881 - acc: 0.5463 - val_loss: 1.7665 - val_acc: 0.5000\n",
      "\n",
      "Epoch 1147/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 31us/step - loss: 1.1643 - acc: 0.5463 - val_loss: 1.7642 - val_acc: 0.5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1148/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 32us/step - loss: 1.2184 - acc: 0.5324 - val_loss: 1.7607 - val_acc: 0.5000\n",
      "\n",
      "Epoch 1149/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 34us/step - loss: 1.1929 - acc: 0.5139 - val_loss: 1.7714 - val_acc: 0.5000\n",
      "\n",
      "Epoch 1150/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 33us/step - loss: 1.2691 - acc: 0.5278 - val_loss: 1.7810 - val_acc: 0.5000\n",
      "\n",
      "Epoch 1151/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 31us/step - loss: 1.1740 - acc: 0.5972 - val_loss: 1.7755 - val_acc: 0.5208\n",
      "\n",
      "Epoch 1152/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 31us/step - loss: 1.1528 - acc: 0.5787 - val_loss: 1.7802 - val_acc: 0.5000\n",
      "\n",
      "Epoch 1153/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 34us/step - loss: 1.1641 - acc: 0.5694 - val_loss: 1.7741 - val_acc: 0.5000\n",
      "\n",
      "Epoch 1154/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 33us/step - loss: 1.1932 - acc: 0.5278 - val_loss: 1.7631 - val_acc: 0.5000\n",
      "\n",
      "Epoch 1155/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 34us/step - loss: 1.2336 - acc: 0.5417 - val_loss: 1.7687 - val_acc: 0.5000\n",
      "\n",
      "Epoch 1156/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 35us/step - loss: 1.2546 - acc: 0.5093 - val_loss: 1.7653 - val_acc: 0.5000\n",
      "\n",
      "Epoch 1157/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 34us/step - loss: 1.1817 - acc: 0.5972 - val_loss: 1.7671 - val_acc: 0.5000\n",
      "\n",
      "Epoch 1158/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 33us/step - loss: 1.1628 - acc: 0.5741 - val_loss: 1.7720 - val_acc: 0.5000\n",
      "\n",
      "Epoch 1159/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 38us/step - loss: 1.2239 - acc: 0.5602 - val_loss: 1.7727 - val_acc: 0.5000\n",
      "\n",
      "Epoch 1160/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 33us/step - loss: 1.1460 - acc: 0.5926 - val_loss: 1.7705 - val_acc: 0.5000\n",
      "\n",
      "Epoch 1161/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 34us/step - loss: 1.2325 - acc: 0.5000 - val_loss: 1.7764 - val_acc: 0.5208\n",
      "\n",
      "Epoch 1162/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 35us/step - loss: 1.2345 - acc: 0.5370 - val_loss: 1.7635 - val_acc: 0.5000\n",
      "\n",
      "Epoch 1163/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 36us/step - loss: 1.1966 - acc: 0.5324 - val_loss: 1.7615 - val_acc: 0.5000\n",
      "\n",
      "Epoch 1164/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 33us/step - loss: 1.2131 - acc: 0.5370 - val_loss: 1.7558 - val_acc: 0.5208\n",
      "\n",
      "Epoch 1165/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 35us/step - loss: 1.2312 - acc: 0.5509 - val_loss: 1.7614 - val_acc: 0.5000\n",
      "\n",
      "Epoch 1166/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 41us/step - loss: 1.2124 - acc: 0.5046 - val_loss: 1.7551 - val_acc: 0.5000\n",
      "\n",
      "Epoch 1167/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 37us/step - loss: 1.2048 - acc: 0.5463 - val_loss: 1.7553 - val_acc: 0.5000\n",
      "\n",
      "Epoch 1168/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 31us/step - loss: 1.2066 - acc: 0.5741 - val_loss: 1.7476 - val_acc: 0.5000\n",
      "\n",
      "Epoch 1169/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 31us/step - loss: 1.1826 - acc: 0.5741 - val_loss: 1.7623 - val_acc: 0.5000\n",
      "\n",
      "Epoch 1170/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 31us/step - loss: 1.1932 - acc: 0.5370 - val_loss: 1.7524 - val_acc: 0.5000\n",
      "\n",
      "Epoch 1171/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 31us/step - loss: 1.1615 - acc: 0.5602 - val_loss: 1.7588 - val_acc: 0.5000\n",
      "\n",
      "Epoch 1172/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 36us/step - loss: 1.1731 - acc: 0.5741 - val_loss: 1.7588 - val_acc: 0.5000\n",
      "\n",
      "Epoch 1173/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 46us/step - loss: 1.1819 - acc: 0.5463 - val_loss: 1.7633 - val_acc: 0.5000\n",
      "\n",
      "Epoch 1174/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 43us/step - loss: 1.1969 - acc: 0.5231 - val_loss: 1.7529 - val_acc: 0.5000\n",
      "\n",
      "Epoch 1175/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 40us/step - loss: 1.1900 - acc: 0.5741 - val_loss: 1.7555 - val_acc: 0.5000\n",
      "\n",
      "Epoch 1176/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 41us/step - loss: 1.1685 - acc: 0.5694 - val_loss: 1.7565 - val_acc: 0.5000\n",
      "\n",
      "Epoch 1177/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 42us/step - loss: 1.1590 - acc: 0.6204 - val_loss: 1.7699 - val_acc: 0.5000\n",
      "\n",
      "Epoch 1178/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 34us/step - loss: 1.2245 - acc: 0.5556 - val_loss: 1.7687 - val_acc: 0.5000\n",
      "\n",
      "Epoch 1179/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 54us/step - loss: 1.2925 - acc: 0.5602 - val_loss: 1.7656 - val_acc: 0.5000\n",
      "\n",
      "Epoch 1180/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 45us/step - loss: 1.1926 - acc: 0.5556 - val_loss: 1.7652 - val_acc: 0.5000\n",
      "\n",
      "Epoch 1181/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 100us/step - loss: 1.1776 - acc: 0.5648 - val_loss: 1.7509 - val_acc: 0.5000\n",
      "\n",
      "Epoch 1182/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 162us/step - loss: 1.1475 - acc: 0.5509 - val_loss: 1.7663 - val_acc: 0.5000\n",
      "\n",
      "Epoch 1183/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 105us/step - loss: 1.1884 - acc: 0.5648 - val_loss: 1.7540 - val_acc: 0.5000\n",
      "\n",
      "Epoch 1184/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 107us/step - loss: 1.1733 - acc: 0.6065 - val_loss: 1.7627 - val_acc: 0.5000\n",
      "\n",
      "Epoch 1185/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 107us/step - loss: 1.1700 - acc: 0.5833 - val_loss: 1.7655 - val_acc: 0.5000\n",
      "\n",
      "Epoch 1186/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 108us/step - loss: 1.2088 - acc: 0.5463 - val_loss: 1.7754 - val_acc: 0.5000\n",
      "\n",
      "Epoch 1187/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 99us/step - loss: 1.1699 - acc: 0.5926 - val_loss: 1.7655 - val_acc: 0.5000\n",
      "\n",
      "Epoch 1188/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 178us/step - loss: 1.1585 - acc: 0.5694 - val_loss: 1.7736 - val_acc: 0.5000\n",
      "\n",
      "Epoch 1189/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 113us/step - loss: 1.1388 - acc: 0.5926 - val_loss: 1.7571 - val_acc: 0.5000\n",
      "\n",
      "Epoch 1190/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 97us/step - loss: 1.1501 - acc: 0.5602 - val_loss: 1.7631 - val_acc: 0.5000\n",
      "\n",
      "Epoch 1191/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 115us/step - loss: 1.2669 - acc: 0.5139 - val_loss: 1.7689 - val_acc: 0.5208\n",
      "\n",
      "Epoch 1192/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 108us/step - loss: 1.1314 - acc: 0.5602 - val_loss: 1.7667 - val_acc: 0.5000\n",
      "\n",
      "Epoch 1193/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 90us/step - loss: 1.1834 - acc: 0.5741 - val_loss: 1.7877 - val_acc: 0.5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1194/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 111us/step - loss: 1.2352 - acc: 0.5463 - val_loss: 1.7884 - val_acc: 0.5000\n",
      "\n",
      "Epoch 1195/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 92us/step - loss: 1.2391 - acc: 0.5556 - val_loss: 1.7702 - val_acc: 0.5000\n",
      "\n",
      "Epoch 1196/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 105us/step - loss: 1.2637 - acc: 0.5185 - val_loss: 1.7583 - val_acc: 0.5000\n",
      "\n",
      "Epoch 1197/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 177us/step - loss: 1.2147 - acc: 0.5463 - val_loss: 1.7598 - val_acc: 0.5000\n",
      "\n",
      "Epoch 1198/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 100us/step - loss: 1.2127 - acc: 0.5417 - val_loss: 1.7586 - val_acc: 0.5000\n",
      "\n",
      "Epoch 1199/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 97us/step - loss: 1.1775 - acc: 0.5602 - val_loss: 1.7629 - val_acc: 0.5000\n",
      "\n",
      "Epoch 1200/1200\n",
      "216/216 [==============================]216/216 [==============================] - 0s 111us/step - loss: 1.1954 - acc: 0.5417 - val_loss: 1.7716 - val_acc: 0.5000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#####VIJETH\n",
    "########## HYPER PARAMETERS\n",
    "batch_size = 512\n",
    "epochs = 1200\n",
    "optimizer = tf.keras.optimizers.Adadelta()\n",
    "keras.initializers.glorot_normal(seed=None)\n",
    "########## HYPER PARAMETERS\n",
    "\n",
    "########## MODEL ARCHITECTURE\n",
    "model = tf.keras.Sequential()\n",
    "model.add(tf.keras.layers.Dense(28, activation='relu',kernel_initializer='orthogonal', input_shape=(100,)))\n",
    "model.add(tf.keras.layers.Dropout(0.5))\n",
    "#model.add(tf.keras.layers.BatchNormalization())\n",
    "#model.add(tf.keras.layers.Dense(8, activation='relu'))\n",
    "#model.add(tf.keras.layers.Dropout(0.2))\n",
    "#model.add(tf.keras.layers.BatchNormalization())\n",
    "#model.add(tf.keras.layers.Dense(16, activation='relu'))#WAS removed \n",
    "model.add(tf.keras.layers.Dense(Class, activation='softmax'))\n",
    "########## MODEL ARCHITECTURE\n",
    "\n",
    "# Print summary\n",
    "model.summary()\n",
    "\n",
    "# compile model for training\n",
    "model.compile(loss='kullback_leibler_divergence',\n",
    "              optimizer=optimizer,\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(X, y_train_one_hot,\n",
    "                    batch_size=batch_size,\n",
    "                    epochs=epochs,\n",
    "                    verbose=1,\n",
    "                    validation_data=(X_test, y_test_one_hot))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7f64ce785fd0>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(history.history['val_acc'], label=\"Test Accuracy\")\n",
    "plt.plot(history.history['acc'], label=\"Training Accuracy\")\n",
    "plt.ylabel('Accuracy ------------->')\n",
    "plt.xlabel('Epochs -------------->')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7f64ce717c88>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(history.history['val_loss'], label=\"Testing Loss\")\n",
    "plt.plot(history.history['loss'], label=\"Training Loss\")\n",
    "plt.ylabel('Loss ------------->')\n",
    "plt.xlabel('Epochs -------------->')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved model to disk\n"
     ]
    }
   ],
   "source": [
    "import datetime\n",
    "now = datetime.datetime.now()\n",
    "TempName = str(now.day) +str(now.month)+ str(now.hour) + str(now.minute)\n",
    "\n",
    "# serialize model to JSON\n",
    "model_json = model.to_json()\n",
    "with open(FilePath + \"Runs/\" + RunFolder + \"/ModelsAndWeights/\"+ TempName +\"Predict_DNN_100FVfromResnet_8Class.json\", \"w\") as json_file:\n",
    "    json_file.write(model_json)\n",
    "# serialize weights to HDF5\n",
    "model.save_weights(FilePath + \"Runs/\" + RunFolder + \"/ModelsAndWeights/\"+ TempName +\"Predict_DNN_100FVfromResnet_8Class.h5\")\n",
    "print(\"Saved model to disk\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
